{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "798603de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,KFold, cross_val_predict, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648c0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb81dc6",
   "metadata": {},
   "source": [
    "## Download All Policies - Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d6d084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Privacy Policies download:\n",
    "websites = ['Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson']\n",
    "\n",
    "sequence_to_classify = []\n",
    "\n",
    "for i in websites:\n",
    "    try:\n",
    "        with open((i+\".txt\"), \"r\") as f:\n",
    "            i = f.readlines()\n",
    "            sequence_to_classify.append(i)\n",
    "    except:\n",
    "        with open((i+\".txt\"), \"r\", encoding='cp1252') as f:\n",
    "            i = f.readlines()\n",
    "            sequence_to_classify.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7e7d1",
   "metadata": {},
   "source": [
    "### Train Set Vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27697e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_train = [[1,2,3,4,5,6,7,8],[1,2,3,4,5,6],[1,3,5,6,7],[1,3,7],[1,2,3,4,6,7]\n",
    "                         ,[1,2,3,4,5,6,7],[1,4,5,6,7],[1,3,5,6,7],[1,2,3,5,6,7],[1,2,3,4,5,6,7]\n",
    "                         ,[1,2,3,5,6,7],[1,3,5,6,7],[1,3,7],[1,2,3,7],[1,3,7]\n",
    "                         ,[1,2,5,6],[1,2,3,4,5,6,7],[1,2,3,4,5,6,7],[1,3,5,7],[1,2,3,6]\n",
    "                         ,[1,3,6,7],[1,2,3,5,6,7,8],[1,2,3,4,5,6,7],[1,3,5,6,7],[1,3,5,6,7,8]\n",
    "                         ,[1,3,5,6,7],[1,2,3,4,5,6,7,8],[1,2,3,4,5,6,7],[1,3,5,6],[1,2,3,5,6,7,8]\n",
    "                         ,[1,2,3,5,6,7,8],[1,2,3,4,5,6,7,8],[1,2,3,5,6,7,8],[1,2,3,4,5,6,7],[1,3,4,5,6,7]\n",
    "                         ,[1,3,5,7],[1,2,3,4,5,6,7,8],[1,3,7],[1,2,3,4,5,6,7,8],[1,2,3,4,5,6,7]\n",
    "                         ,[1,2,3,5,7,8],[1,3,7],[1,3,5,7,8],[1,3,4,5,6,7,8],[1,2,3,6,7]\n",
    "                         ,[1,3,5,6,7,8],[1,2,3,4,5,6,7],[1,3,5,6,7,8],[1,3,5,6,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c92b236",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_train_personal = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "data_collection_train_media = [1,1,0,0,1,1,0,0,1,1,1,0,0,1,0,1,1,1,0,1,0,1,1,0,0,0,1,1,0,1,1,1,1,1,0,0,1,0,1,1,1,0,0,0,1,0,1,0,0]\n",
    "data_collection_train_browser = [1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "data_collection_train_voice = [1,1,0,0,1,1,1,0,0,1,0,0,0,0,0,0,1,1,0,0,0,0,1,0,0,0,1,1,0,0,0,1,0,1,1,0,1,0,1,1,0,0,0,1,0,0,1,0,0]\n",
    "data_collection_train_payments = [1,1,1,0,0,1,1,1,1,1,1,1,0,0,0,1,1,1,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,0,1,1,1,1]\n",
    "data_collection_train_location = [1,1,1,0,1,1,1,1,1,1,1,1,0,0,0,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,1,0,0,0,1,1,1,1,1,1]\n",
    "data_collection_train_IP = [1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,0,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "data_collection_train_passward = [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,1,0,0,1,1,1,1,0,0,0,1,0,1,0,1,0,1,1,0,1,0,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707cd9b",
   "metadata": {},
   "source": [
    "### Data Security Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2736c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>we save your name, address, phone number, birth date, or email address</th>\n",
       "      <th>we are not collect your name, address, phone number, birth date, and email address</th>\n",
       "      <th>we collect your personal data</th>\n",
       "      <th>we do not collect your personal data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.281912</td>\n",
       "      <td>0.302289</td>\n",
       "      <td>0.981916</td>\n",
       "      <td>0.267769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.260433</td>\n",
       "      <td>0.25161</td>\n",
       "      <td>0.953546</td>\n",
       "      <td>0.732466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.292289</td>\n",
       "      <td>0.325571</td>\n",
       "      <td>0.86903</td>\n",
       "      <td>0.147927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.311984</td>\n",
       "      <td>0.311889</td>\n",
       "      <td>0.982988</td>\n",
       "      <td>0.906464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.268777</td>\n",
       "      <td>0.289224</td>\n",
       "      <td>0.892116</td>\n",
       "      <td>0.755127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.298692</td>\n",
       "      <td>0.350057</td>\n",
       "      <td>0.946936</td>\n",
       "      <td>0.372887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.37765</td>\n",
       "      <td>0.376907</td>\n",
       "      <td>0.934453</td>\n",
       "      <td>0.249633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.298922</td>\n",
       "      <td>0.298791</td>\n",
       "      <td>0.977923</td>\n",
       "      <td>0.221816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.321984</td>\n",
       "      <td>0.312714</td>\n",
       "      <td>0.990194</td>\n",
       "      <td>0.798815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.349268</td>\n",
       "      <td>0.342385</td>\n",
       "      <td>0.786127</td>\n",
       "      <td>0.772053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.246704</td>\n",
       "      <td>0.26763</td>\n",
       "      <td>0.964243</td>\n",
       "      <td>0.78756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.320469</td>\n",
       "      <td>0.31457</td>\n",
       "      <td>0.995617</td>\n",
       "      <td>0.880654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.288267</td>\n",
       "      <td>0.329812</td>\n",
       "      <td>0.955284</td>\n",
       "      <td>0.09701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.347011</td>\n",
       "      <td>0.38621</td>\n",
       "      <td>0.987306</td>\n",
       "      <td>0.627603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.263371</td>\n",
       "      <td>0.269412</td>\n",
       "      <td>0.940396</td>\n",
       "      <td>0.387642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.313896</td>\n",
       "      <td>0.346612</td>\n",
       "      <td>0.985384</td>\n",
       "      <td>0.263371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.402186</td>\n",
       "      <td>0.433395</td>\n",
       "      <td>0.974166</td>\n",
       "      <td>0.500394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.252172</td>\n",
       "      <td>0.288364</td>\n",
       "      <td>0.991237</td>\n",
       "      <td>0.070637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.380074</td>\n",
       "      <td>0.342996</td>\n",
       "      <td>0.960212</td>\n",
       "      <td>0.834135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.432736</td>\n",
       "      <td>0.470742</td>\n",
       "      <td>0.945448</td>\n",
       "      <td>0.714015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.272048</td>\n",
       "      <td>0.286274</td>\n",
       "      <td>0.997564</td>\n",
       "      <td>0.948855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.281423</td>\n",
       "      <td>0.347139</td>\n",
       "      <td>0.90014</td>\n",
       "      <td>0.080936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.311263</td>\n",
       "      <td>0.346854</td>\n",
       "      <td>0.965768</td>\n",
       "      <td>0.556987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.268643</td>\n",
       "      <td>0.273588</td>\n",
       "      <td>0.962156</td>\n",
       "      <td>0.721267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.318994</td>\n",
       "      <td>0.320694</td>\n",
       "      <td>0.964723</td>\n",
       "      <td>0.671753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.243461</td>\n",
       "      <td>0.239156</td>\n",
       "      <td>0.964575</td>\n",
       "      <td>0.767153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.257391</td>\n",
       "      <td>0.241529</td>\n",
       "      <td>0.948684</td>\n",
       "      <td>0.871323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.257789</td>\n",
       "      <td>0.247372</td>\n",
       "      <td>0.96716</td>\n",
       "      <td>0.509389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.447161</td>\n",
       "      <td>0.504538</td>\n",
       "      <td>0.98271</td>\n",
       "      <td>0.532586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.278256</td>\n",
       "      <td>0.290089</td>\n",
       "      <td>0.977942</td>\n",
       "      <td>0.89787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.410191</td>\n",
       "      <td>0.379337</td>\n",
       "      <td>0.959373</td>\n",
       "      <td>0.929364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.259655</td>\n",
       "      <td>0.274151</td>\n",
       "      <td>0.957352</td>\n",
       "      <td>0.211364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.396892</td>\n",
       "      <td>0.426519</td>\n",
       "      <td>0.873466</td>\n",
       "      <td>0.435124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.342859</td>\n",
       "      <td>0.380593</td>\n",
       "      <td>0.995571</td>\n",
       "      <td>0.834033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.309833</td>\n",
       "      <td>0.318723</td>\n",
       "      <td>0.957473</td>\n",
       "      <td>0.716836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.332875</td>\n",
       "      <td>0.32984</td>\n",
       "      <td>0.944981</td>\n",
       "      <td>0.776881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.245396</td>\n",
       "      <td>0.263383</td>\n",
       "      <td>0.993008</td>\n",
       "      <td>0.452589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.28059</td>\n",
       "      <td>0.278013</td>\n",
       "      <td>0.949852</td>\n",
       "      <td>0.746588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.281005</td>\n",
       "      <td>0.300307</td>\n",
       "      <td>0.985341</td>\n",
       "      <td>0.19119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.240131</td>\n",
       "      <td>0.276073</td>\n",
       "      <td>0.988368</td>\n",
       "      <td>0.804385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.422164</td>\n",
       "      <td>0.4306</td>\n",
       "      <td>0.953435</td>\n",
       "      <td>0.427062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.387325</td>\n",
       "      <td>0.311306</td>\n",
       "      <td>0.695291</td>\n",
       "      <td>0.236177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.308725</td>\n",
       "      <td>0.317084</td>\n",
       "      <td>0.804563</td>\n",
       "      <td>0.133814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.297702</td>\n",
       "      <td>0.288474</td>\n",
       "      <td>0.952536</td>\n",
       "      <td>0.48525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.339886</td>\n",
       "      <td>0.339095</td>\n",
       "      <td>0.934945</td>\n",
       "      <td>0.750303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.269061</td>\n",
       "      <td>0.270133</td>\n",
       "      <td>0.964908</td>\n",
       "      <td>0.741046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.317921</td>\n",
       "      <td>0.343005</td>\n",
       "      <td>0.961361</td>\n",
       "      <td>0.75212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.351477</td>\n",
       "      <td>0.294885</td>\n",
       "      <td>0.570659</td>\n",
       "      <td>0.887281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.366774</td>\n",
       "      <td>0.383467</td>\n",
       "      <td>0.972392</td>\n",
       "      <td>0.396855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  we save your name, address, phone number, birth date, or email address  \\\n",
       "Privacy Policy                                                                             \n",
       "Google                                                      0.281912                       \n",
       "Aws                                                         0.260433                       \n",
       "AliExpress                                                  0.292289                       \n",
       "Meta                                                        0.311984                       \n",
       "TikTok                                                      0.268777                       \n",
       "YouTube                                                     0.298692                       \n",
       "Waze                                                         0.37765                       \n",
       "Wix                                                         0.298922                       \n",
       "Bookings                                                    0.321984                       \n",
       "whatsapp                                                    0.349268                       \n",
       "apple                                                       0.246704                       \n",
       "wolt                                                        0.320469                       \n",
       "Visa                                                        0.288267                       \n",
       "Mastercard                                                  0.347011                       \n",
       "AirBNB                                                      0.263371                       \n",
       "uber                                                        0.313896                       \n",
       "Spotify                                                     0.402186                       \n",
       "samsung                                                     0.252172                       \n",
       "Wordpress                                                   0.380074                       \n",
       "instagram                                                   0.432736                       \n",
       "MacDonalds                                                  0.272048                       \n",
       "FDA                                                         0.281423                       \n",
       "Oracle                                                      0.311263                       \n",
       "Zara                                                        0.268643                       \n",
       "cocacola                                                    0.318994                       \n",
       "Xiaomi                                                      0.243461                       \n",
       "Nasdaq                                                      0.257391                       \n",
       "Walmart                                                     0.257789                       \n",
       "AirCanada                                                   0.447161                       \n",
       "Lufthansa                                                   0.278256                       \n",
       "shopify                                                     0.410191                       \n",
       "Netflix                                                     0.259655                       \n",
       "adobe                                                       0.396892                       \n",
       "Starbucks                                                   0.342859                       \n",
       "Shoppers                                                    0.309833                       \n",
       "Decathlon                                                   0.332875                       \n",
       "waltdisney                                                  0.245396                       \n",
       "AmericanEagle                                                0.28059                       \n",
       "lululemon                                                   0.281005                       \n",
       "SAP                                                         0.240131                       \n",
       "JetBrains                                                   0.422164                       \n",
       "MySQLCode                                                   0.387325                       \n",
       "Cadens                                                      0.308725                       \n",
       "EpicGames                                                   0.297702                       \n",
       "unitedHealthGroup                                           0.339886                       \n",
       "Slack                                                       0.269061                       \n",
       "SalesForce                                                  0.317921                       \n",
       "JPMorgan                                                    0.351477                       \n",
       "JohnsonAndJohnson                                           0.366774                       \n",
       "\n",
       "                  we are not collect your name, address, phone number, birth date, and email address  \\\n",
       "Privacy Policy                                                                                         \n",
       "Google                                                      0.302289                                   \n",
       "Aws                                                          0.25161                                   \n",
       "AliExpress                                                  0.325571                                   \n",
       "Meta                                                        0.311889                                   \n",
       "TikTok                                                      0.289224                                   \n",
       "YouTube                                                     0.350057                                   \n",
       "Waze                                                        0.376907                                   \n",
       "Wix                                                         0.298791                                   \n",
       "Bookings                                                    0.312714                                   \n",
       "whatsapp                                                    0.342385                                   \n",
       "apple                                                        0.26763                                   \n",
       "wolt                                                         0.31457                                   \n",
       "Visa                                                        0.329812                                   \n",
       "Mastercard                                                   0.38621                                   \n",
       "AirBNB                                                      0.269412                                   \n",
       "uber                                                        0.346612                                   \n",
       "Spotify                                                     0.433395                                   \n",
       "samsung                                                     0.288364                                   \n",
       "Wordpress                                                   0.342996                                   \n",
       "instagram                                                   0.470742                                   \n",
       "MacDonalds                                                  0.286274                                   \n",
       "FDA                                                         0.347139                                   \n",
       "Oracle                                                      0.346854                                   \n",
       "Zara                                                        0.273588                                   \n",
       "cocacola                                                    0.320694                                   \n",
       "Xiaomi                                                      0.239156                                   \n",
       "Nasdaq                                                      0.241529                                   \n",
       "Walmart                                                     0.247372                                   \n",
       "AirCanada                                                   0.504538                                   \n",
       "Lufthansa                                                   0.290089                                   \n",
       "shopify                                                     0.379337                                   \n",
       "Netflix                                                     0.274151                                   \n",
       "adobe                                                       0.426519                                   \n",
       "Starbucks                                                   0.380593                                   \n",
       "Shoppers                                                    0.318723                                   \n",
       "Decathlon                                                    0.32984                                   \n",
       "waltdisney                                                  0.263383                                   \n",
       "AmericanEagle                                               0.278013                                   \n",
       "lululemon                                                   0.300307                                   \n",
       "SAP                                                         0.276073                                   \n",
       "JetBrains                                                     0.4306                                   \n",
       "MySQLCode                                                   0.311306                                   \n",
       "Cadens                                                      0.317084                                   \n",
       "EpicGames                                                   0.288474                                   \n",
       "unitedHealthGroup                                           0.339095                                   \n",
       "Slack                                                       0.270133                                   \n",
       "SalesForce                                                  0.343005                                   \n",
       "JPMorgan                                                    0.294885                                   \n",
       "JohnsonAndJohnson                                           0.383467                                   \n",
       "\n",
       "                  we collect your personal data  \\\n",
       "Privacy Policy                                    \n",
       "Google                                 0.981916   \n",
       "Aws                                    0.953546   \n",
       "AliExpress                              0.86903   \n",
       "Meta                                   0.982988   \n",
       "TikTok                                 0.892116   \n",
       "YouTube                                0.946936   \n",
       "Waze                                   0.934453   \n",
       "Wix                                    0.977923   \n",
       "Bookings                               0.990194   \n",
       "whatsapp                               0.786127   \n",
       "apple                                  0.964243   \n",
       "wolt                                   0.995617   \n",
       "Visa                                   0.955284   \n",
       "Mastercard                             0.987306   \n",
       "AirBNB                                 0.940396   \n",
       "uber                                   0.985384   \n",
       "Spotify                                0.974166   \n",
       "samsung                                0.991237   \n",
       "Wordpress                              0.960212   \n",
       "instagram                              0.945448   \n",
       "MacDonalds                             0.997564   \n",
       "FDA                                     0.90014   \n",
       "Oracle                                 0.965768   \n",
       "Zara                                   0.962156   \n",
       "cocacola                               0.964723   \n",
       "Xiaomi                                 0.964575   \n",
       "Nasdaq                                 0.948684   \n",
       "Walmart                                 0.96716   \n",
       "AirCanada                               0.98271   \n",
       "Lufthansa                              0.977942   \n",
       "shopify                                0.959373   \n",
       "Netflix                                0.957352   \n",
       "adobe                                  0.873466   \n",
       "Starbucks                              0.995571   \n",
       "Shoppers                               0.957473   \n",
       "Decathlon                              0.944981   \n",
       "waltdisney                             0.993008   \n",
       "AmericanEagle                          0.949852   \n",
       "lululemon                              0.985341   \n",
       "SAP                                    0.988368   \n",
       "JetBrains                              0.953435   \n",
       "MySQLCode                              0.695291   \n",
       "Cadens                                 0.804563   \n",
       "EpicGames                              0.952536   \n",
       "unitedHealthGroup                      0.934945   \n",
       "Slack                                  0.964908   \n",
       "SalesForce                             0.961361   \n",
       "JPMorgan                               0.570659   \n",
       "JohnsonAndJohnson                      0.972392   \n",
       "\n",
       "                  we do not collect your personal data  \n",
       "Privacy Policy                                          \n",
       "Google                                        0.267769  \n",
       "Aws                                           0.732466  \n",
       "AliExpress                                    0.147927  \n",
       "Meta                                          0.906464  \n",
       "TikTok                                        0.755127  \n",
       "YouTube                                       0.372887  \n",
       "Waze                                          0.249633  \n",
       "Wix                                           0.221816  \n",
       "Bookings                                      0.798815  \n",
       "whatsapp                                      0.772053  \n",
       "apple                                          0.78756  \n",
       "wolt                                          0.880654  \n",
       "Visa                                           0.09701  \n",
       "Mastercard                                    0.627603  \n",
       "AirBNB                                        0.387642  \n",
       "uber                                          0.263371  \n",
       "Spotify                                       0.500394  \n",
       "samsung                                       0.070637  \n",
       "Wordpress                                     0.834135  \n",
       "instagram                                     0.714015  \n",
       "MacDonalds                                    0.948855  \n",
       "FDA                                           0.080936  \n",
       "Oracle                                        0.556987  \n",
       "Zara                                          0.721267  \n",
       "cocacola                                      0.671753  \n",
       "Xiaomi                                        0.767153  \n",
       "Nasdaq                                        0.871323  \n",
       "Walmart                                       0.509389  \n",
       "AirCanada                                     0.532586  \n",
       "Lufthansa                                      0.89787  \n",
       "shopify                                       0.929364  \n",
       "Netflix                                       0.211364  \n",
       "adobe                                         0.435124  \n",
       "Starbucks                                     0.834033  \n",
       "Shoppers                                      0.716836  \n",
       "Decathlon                                     0.776881  \n",
       "waltdisney                                    0.452589  \n",
       "AmericanEagle                                 0.746588  \n",
       "lululemon                                      0.19119  \n",
       "SAP                                           0.804385  \n",
       "JetBrains                                     0.427062  \n",
       "MySQLCode                                     0.236177  \n",
       "Cadens                                        0.133814  \n",
       "EpicGames                                      0.48525  \n",
       "unitedHealthGroup                             0.750303  \n",
       "Slack                                         0.741046  \n",
       "SalesForce                                     0.75212  \n",
       "JPMorgan                                      0.887281  \n",
       "JohnsonAndJohnson                             0.396855  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data_security Matrix - _personal [1]:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'we save your name, address, phone number, birth date, or email address'\n",
    "           ,'we are not collect your name, address, phone number, birth date, and email address'\n",
    "           ,'we collect your personal data'\n",
    "           ,'we do not collect your personal data']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_ML_personal = pd.DataFrame(columns = Phrases)\n",
    "matrix_data_collection_ML_personal['Privacy Policy'] = websites\n",
    "matrix_data_collection_ML_personal.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_collection_ML_personal:\n",
    "        matrix_data_collection_ML_personal.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "\n",
    "matrix_data_collection_ML_personal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf7ced",
   "metadata": {},
   "source": [
    "### Test The Model - ML - Personal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53ffb93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "Random Forest Classifaier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "KNN Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "neural_network Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_data_collection_ML_personal.iloc[:35,:] \n",
    "X_test = matrix_data_collection_ML_personal.iloc[34:,:]\n",
    "y_train = data_collection_train_personal[:35]\n",
    "y_test = data_collection_train_personal[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "# ##Logistic Reg Classifier\n",
    "# clf = LogisticRegression()\n",
    "# clf.fit(X_train, y_train)\n",
    "# pred_clf = clf.predict(X_test)\n",
    "# print('Logistic Reg Classifier:', pred_clf)\n",
    "# print(classification_report(y_test, pred_clf))\n",
    "\n",
    "# ##SVM\n",
    "# SVM = SVC(kernel='linear')\n",
    "# SVM = SVM.fit(X_train, y_train)\n",
    "# pred_SVM = SVM.predict(X_test)\n",
    "# print('SVM Classifier:', pred_SVM)\n",
    "# print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN Classifier:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network Classifier:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e5146bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_personal = pred_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af7424f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>we save your media</th>\n",
       "      <th>we are not collect your media</th>\n",
       "      <th>we collect your photos and images</th>\n",
       "      <th>we are not saving your photos and images</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.937889</td>\n",
       "      <td>0.637209</td>\n",
       "      <td>0.955504</td>\n",
       "      <td>0.146648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.909985</td>\n",
       "      <td>0.863607</td>\n",
       "      <td>0.778217</td>\n",
       "      <td>0.398459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.685809</td>\n",
       "      <td>0.221852</td>\n",
       "      <td>0.777231</td>\n",
       "      <td>0.044111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.954075</td>\n",
       "      <td>0.904198</td>\n",
       "      <td>0.867779</td>\n",
       "      <td>0.367086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.863993</td>\n",
       "      <td>0.707232</td>\n",
       "      <td>0.877363</td>\n",
       "      <td>0.344582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.923091</td>\n",
       "      <td>0.419085</td>\n",
       "      <td>0.902374</td>\n",
       "      <td>0.149081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.835655</td>\n",
       "      <td>0.526477</td>\n",
       "      <td>0.59618</td>\n",
       "      <td>0.044798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.635409</td>\n",
       "      <td>0.805327</td>\n",
       "      <td>0.072721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.917105</td>\n",
       "      <td>0.883325</td>\n",
       "      <td>0.909622</td>\n",
       "      <td>0.106977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.809266</td>\n",
       "      <td>0.801679</td>\n",
       "      <td>0.42667</td>\n",
       "      <td>0.192217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.945298</td>\n",
       "      <td>0.854641</td>\n",
       "      <td>0.948036</td>\n",
       "      <td>0.337726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.977879</td>\n",
       "      <td>0.962689</td>\n",
       "      <td>0.928492</td>\n",
       "      <td>0.267172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.885743</td>\n",
       "      <td>0.242863</td>\n",
       "      <td>0.884605</td>\n",
       "      <td>0.090286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.949009</td>\n",
       "      <td>0.507975</td>\n",
       "      <td>0.972302</td>\n",
       "      <td>0.233779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.891232</td>\n",
       "      <td>0.704276</td>\n",
       "      <td>0.882567</td>\n",
       "      <td>0.245655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.935844</td>\n",
       "      <td>0.509088</td>\n",
       "      <td>0.923692</td>\n",
       "      <td>0.084402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.918053</td>\n",
       "      <td>0.663385</td>\n",
       "      <td>0.789944</td>\n",
       "      <td>0.088937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.925218</td>\n",
       "      <td>0.493011</td>\n",
       "      <td>0.949396</td>\n",
       "      <td>0.05941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.89317</td>\n",
       "      <td>0.794923</td>\n",
       "      <td>0.65697</td>\n",
       "      <td>0.26559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.938397</td>\n",
       "      <td>0.64814</td>\n",
       "      <td>0.926822</td>\n",
       "      <td>0.422934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.991804</td>\n",
       "      <td>0.961583</td>\n",
       "      <td>0.983428</td>\n",
       "      <td>0.266085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.812026</td>\n",
       "      <td>0.237224</td>\n",
       "      <td>0.511815</td>\n",
       "      <td>0.073922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.892954</td>\n",
       "      <td>0.710876</td>\n",
       "      <td>0.88296</td>\n",
       "      <td>0.147355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.904609</td>\n",
       "      <td>0.852042</td>\n",
       "      <td>0.897534</td>\n",
       "      <td>0.278715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.888352</td>\n",
       "      <td>0.788943</td>\n",
       "      <td>0.912511</td>\n",
       "      <td>0.418676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.946533</td>\n",
       "      <td>0.78527</td>\n",
       "      <td>0.963497</td>\n",
       "      <td>0.405208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.894039</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.875472</td>\n",
       "      <td>0.416696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.741846</td>\n",
       "      <td>0.49198</td>\n",
       "      <td>0.59216</td>\n",
       "      <td>0.104323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.919477</td>\n",
       "      <td>0.618855</td>\n",
       "      <td>0.905933</td>\n",
       "      <td>0.138689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.957486</td>\n",
       "      <td>0.88776</td>\n",
       "      <td>0.90636</td>\n",
       "      <td>0.571736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.868522</td>\n",
       "      <td>0.91133</td>\n",
       "      <td>0.782923</td>\n",
       "      <td>0.43263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.844826</td>\n",
       "      <td>0.684043</td>\n",
       "      <td>0.84687</td>\n",
       "      <td>0.095674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.737399</td>\n",
       "      <td>0.653877</td>\n",
       "      <td>0.831471</td>\n",
       "      <td>0.168176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.985976</td>\n",
       "      <td>0.889906</td>\n",
       "      <td>0.953379</td>\n",
       "      <td>0.37541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.809049</td>\n",
       "      <td>0.499916</td>\n",
       "      <td>0.822756</td>\n",
       "      <td>0.142508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.858367</td>\n",
       "      <td>0.797982</td>\n",
       "      <td>0.793519</td>\n",
       "      <td>0.27617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.979118</td>\n",
       "      <td>0.910652</td>\n",
       "      <td>0.982051</td>\n",
       "      <td>0.558452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.887813</td>\n",
       "      <td>0.873444</td>\n",
       "      <td>0.927153</td>\n",
       "      <td>0.291664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.928653</td>\n",
       "      <td>0.506877</td>\n",
       "      <td>0.865442</td>\n",
       "      <td>0.034097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.972686</td>\n",
       "      <td>0.832862</td>\n",
       "      <td>0.930839</td>\n",
       "      <td>0.275431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.776306</td>\n",
       "      <td>0.623297</td>\n",
       "      <td>0.9178</td>\n",
       "      <td>0.121571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.578604</td>\n",
       "      <td>0.316878</td>\n",
       "      <td>0.427231</td>\n",
       "      <td>0.07079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.666627</td>\n",
       "      <td>0.201916</td>\n",
       "      <td>0.599149</td>\n",
       "      <td>0.037513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.836215</td>\n",
       "      <td>0.735579</td>\n",
       "      <td>0.846211</td>\n",
       "      <td>0.130198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.841708</td>\n",
       "      <td>0.754909</td>\n",
       "      <td>0.767315</td>\n",
       "      <td>0.249726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.907662</td>\n",
       "      <td>0.776206</td>\n",
       "      <td>0.843714</td>\n",
       "      <td>0.233619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.908608</td>\n",
       "      <td>0.761861</td>\n",
       "      <td>0.912886</td>\n",
       "      <td>0.333686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.248323</td>\n",
       "      <td>0.467269</td>\n",
       "      <td>0.878182</td>\n",
       "      <td>0.083383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.894138</td>\n",
       "      <td>0.552852</td>\n",
       "      <td>0.905755</td>\n",
       "      <td>0.101018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  we save your media we are not collect your media  \\\n",
       "Privacy Policy                                                       \n",
       "Google                      0.937889                      0.637209   \n",
       "Aws                         0.909985                      0.863607   \n",
       "AliExpress                  0.685809                      0.221852   \n",
       "Meta                        0.954075                      0.904198   \n",
       "TikTok                      0.863993                      0.707232   \n",
       "YouTube                     0.923091                      0.419085   \n",
       "Waze                        0.835655                      0.526477   \n",
       "Wix                         0.836957                      0.635409   \n",
       "Bookings                    0.917105                      0.883325   \n",
       "whatsapp                    0.809266                      0.801679   \n",
       "apple                       0.945298                      0.854641   \n",
       "wolt                        0.977879                      0.962689   \n",
       "Visa                        0.885743                      0.242863   \n",
       "Mastercard                  0.949009                      0.507975   \n",
       "AirBNB                      0.891232                      0.704276   \n",
       "uber                        0.935844                      0.509088   \n",
       "Spotify                     0.918053                      0.663385   \n",
       "samsung                     0.925218                      0.493011   \n",
       "Wordpress                    0.89317                      0.794923   \n",
       "instagram                   0.938397                       0.64814   \n",
       "MacDonalds                  0.991804                      0.961583   \n",
       "FDA                         0.812026                      0.237224   \n",
       "Oracle                      0.892954                      0.710876   \n",
       "Zara                        0.904609                      0.852042   \n",
       "cocacola                    0.888352                      0.788943   \n",
       "Xiaomi                      0.946533                       0.78527   \n",
       "Nasdaq                      0.894039                         0.858   \n",
       "Walmart                     0.741846                       0.49198   \n",
       "AirCanada                   0.919477                      0.618855   \n",
       "Lufthansa                   0.957486                       0.88776   \n",
       "shopify                     0.868522                       0.91133   \n",
       "Netflix                     0.844826                      0.684043   \n",
       "adobe                       0.737399                      0.653877   \n",
       "Starbucks                   0.985976                      0.889906   \n",
       "Shoppers                    0.809049                      0.499916   \n",
       "Decathlon                   0.858367                      0.797982   \n",
       "waltdisney                  0.979118                      0.910652   \n",
       "AmericanEagle               0.887813                      0.873444   \n",
       "lululemon                   0.928653                      0.506877   \n",
       "SAP                         0.972686                      0.832862   \n",
       "JetBrains                   0.776306                      0.623297   \n",
       "MySQLCode                   0.578604                      0.316878   \n",
       "Cadens                      0.666627                      0.201916   \n",
       "EpicGames                   0.836215                      0.735579   \n",
       "unitedHealthGroup           0.841708                      0.754909   \n",
       "Slack                       0.907662                      0.776206   \n",
       "SalesForce                  0.908608                      0.761861   \n",
       "JPMorgan                    0.248323                      0.467269   \n",
       "JohnsonAndJohnson           0.894138                      0.552852   \n",
       "\n",
       "                  we collect your photos and images  \\\n",
       "Privacy Policy                                        \n",
       "Google                                     0.955504   \n",
       "Aws                                        0.778217   \n",
       "AliExpress                                 0.777231   \n",
       "Meta                                       0.867779   \n",
       "TikTok                                     0.877363   \n",
       "YouTube                                    0.902374   \n",
       "Waze                                        0.59618   \n",
       "Wix                                        0.805327   \n",
       "Bookings                                   0.909622   \n",
       "whatsapp                                    0.42667   \n",
       "apple                                      0.948036   \n",
       "wolt                                       0.928492   \n",
       "Visa                                       0.884605   \n",
       "Mastercard                                 0.972302   \n",
       "AirBNB                                     0.882567   \n",
       "uber                                       0.923692   \n",
       "Spotify                                    0.789944   \n",
       "samsung                                    0.949396   \n",
       "Wordpress                                   0.65697   \n",
       "instagram                                  0.926822   \n",
       "MacDonalds                                 0.983428   \n",
       "FDA                                        0.511815   \n",
       "Oracle                                      0.88296   \n",
       "Zara                                       0.897534   \n",
       "cocacola                                   0.912511   \n",
       "Xiaomi                                     0.963497   \n",
       "Nasdaq                                     0.875472   \n",
       "Walmart                                     0.59216   \n",
       "AirCanada                                  0.905933   \n",
       "Lufthansa                                   0.90636   \n",
       "shopify                                    0.782923   \n",
       "Netflix                                     0.84687   \n",
       "adobe                                      0.831471   \n",
       "Starbucks                                  0.953379   \n",
       "Shoppers                                   0.822756   \n",
       "Decathlon                                  0.793519   \n",
       "waltdisney                                 0.982051   \n",
       "AmericanEagle                              0.927153   \n",
       "lululemon                                  0.865442   \n",
       "SAP                                        0.930839   \n",
       "JetBrains                                    0.9178   \n",
       "MySQLCode                                  0.427231   \n",
       "Cadens                                     0.599149   \n",
       "EpicGames                                  0.846211   \n",
       "unitedHealthGroup                          0.767315   \n",
       "Slack                                      0.843714   \n",
       "SalesForce                                 0.912886   \n",
       "JPMorgan                                   0.878182   \n",
       "JohnsonAndJohnson                          0.905755   \n",
       "\n",
       "                  we are not saving your photos and images  \n",
       "Privacy Policy                                              \n",
       "Google                                            0.146648  \n",
       "Aws                                               0.398459  \n",
       "AliExpress                                        0.044111  \n",
       "Meta                                              0.367086  \n",
       "TikTok                                            0.344582  \n",
       "YouTube                                           0.149081  \n",
       "Waze                                              0.044798  \n",
       "Wix                                               0.072721  \n",
       "Bookings                                          0.106977  \n",
       "whatsapp                                          0.192217  \n",
       "apple                                             0.337726  \n",
       "wolt                                              0.267172  \n",
       "Visa                                              0.090286  \n",
       "Mastercard                                        0.233779  \n",
       "AirBNB                                            0.245655  \n",
       "uber                                              0.084402  \n",
       "Spotify                                           0.088937  \n",
       "samsung                                            0.05941  \n",
       "Wordpress                                          0.26559  \n",
       "instagram                                         0.422934  \n",
       "MacDonalds                                        0.266085  \n",
       "FDA                                               0.073922  \n",
       "Oracle                                            0.147355  \n",
       "Zara                                              0.278715  \n",
       "cocacola                                          0.418676  \n",
       "Xiaomi                                            0.405208  \n",
       "Nasdaq                                            0.416696  \n",
       "Walmart                                           0.104323  \n",
       "AirCanada                                         0.138689  \n",
       "Lufthansa                                         0.571736  \n",
       "shopify                                            0.43263  \n",
       "Netflix                                           0.095674  \n",
       "adobe                                             0.168176  \n",
       "Starbucks                                          0.37541  \n",
       "Shoppers                                          0.142508  \n",
       "Decathlon                                          0.27617  \n",
       "waltdisney                                        0.558452  \n",
       "AmericanEagle                                     0.291664  \n",
       "lululemon                                         0.034097  \n",
       "SAP                                               0.275431  \n",
       "JetBrains                                         0.121571  \n",
       "MySQLCode                                          0.07079  \n",
       "Cadens                                            0.037513  \n",
       "EpicGames                                         0.130198  \n",
       "unitedHealthGroup                                 0.249726  \n",
       "Slack                                             0.233619  \n",
       "SalesForce                                        0.333686  \n",
       "JPMorgan                                          0.083383  \n",
       "JohnsonAndJohnson                                 0.101018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data_security Matrix - _media [2]:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'we save your media'\n",
    "           ,'we are not collect your media'\n",
    "           ,'we collect your photos and images'\n",
    "           ,'we are not saving your photos and images']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_ML_media = pd.DataFrame(columns = Phrases)\n",
    "matrix_data_collection_ML_media['Privacy Policy'] = websites\n",
    "matrix_data_collection_ML_media.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_collection_ML_media:\n",
    "        matrix_data_collection_ML_media.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "    \n",
    "matrix_data_collection_ML_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d75cbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [0 0 2 0 1 1 0 1 0 2 0 1 1 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71         9\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.42      0.28      0.32        15\n",
      "weighted avg       0.65      0.47      0.52        15\n",
      "\n",
      "Random Forest Classifaier: [0 0 2 1 1 0 0 1 0 2 0 1 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56         9\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.40        15\n",
      "   macro avg       0.35      0.24      0.27        15\n",
      "weighted avg       0.53      0.40      0.43        15\n",
      "\n",
      "Logistic Reg Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       9.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       6.0\n",
      "\n",
      "    accuracy                           0.00      15.0\n",
      "   macro avg       0.00      0.00      0.00      15.0\n",
      "weighted avg       0.00      0.00      0.00      15.0\n",
      "\n",
      "SVM Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       9.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "           2       0.00      0.00      0.00       6.0\n",
      "\n",
      "    accuracy                           0.00      15.0\n",
      "   macro avg       0.00      0.00      0.00      15.0\n",
      "weighted avg       0.00      0.00      0.00      15.0\n",
      "\n",
      "KNN Classifier: [0 0 0 0 1 0 0 0 0 1 0 1 0 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60         9\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.40        15\n",
      "   macro avg       0.18      0.22      0.20        15\n",
      "weighted avg       0.33      0.40      0.36        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural_network Classifier: [1 0 2 0 1 0 0 1 1 0 1 1 0 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.50         9\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.52      0.20      0.26        15\n",
      "weighted avg       0.74      0.33      0.41        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_data_collection_ML_media.iloc[:35,:] \n",
    "X_test = matrix_data_collection_ML_media.iloc[34:,:]\n",
    "y_train = data_collection_train_media[:35]\n",
    "y_test = data_collection_train_media[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "##Logistic Reg Classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "print('Logistic Reg Classifier:', pred_clf)\n",
    "print(classification_report(y_test, pred_clf))\n",
    "\n",
    "##SVM\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM = SVM.fit(X_train, y_train)\n",
    "pred_SVM = SVM.predict(X_test)\n",
    "print('SVM Classifier:', pred_SVM)\n",
    "print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN Classifier:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network Classifier:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b2eebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_media = pred_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7136d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>we save your browsing history</th>\n",
       "      <th>we save your browsing preferences</th>\n",
       "      <th>we are not collect your browsing history</th>\n",
       "      <th>we are not collect your browsing preferences</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.844826</td>\n",
       "      <td>0.886259</td>\n",
       "      <td>0.385589</td>\n",
       "      <td>0.591475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.906165</td>\n",
       "      <td>0.908969</td>\n",
       "      <td>0.805677</td>\n",
       "      <td>0.818994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.737969</td>\n",
       "      <td>0.682618</td>\n",
       "      <td>0.179964</td>\n",
       "      <td>0.166785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.946151</td>\n",
       "      <td>0.931737</td>\n",
       "      <td>0.91018</td>\n",
       "      <td>0.89538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.778982</td>\n",
       "      <td>0.816761</td>\n",
       "      <td>0.645819</td>\n",
       "      <td>0.690651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.896308</td>\n",
       "      <td>0.897105</td>\n",
       "      <td>0.481192</td>\n",
       "      <td>0.497081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.728593</td>\n",
       "      <td>0.781011</td>\n",
       "      <td>0.325879</td>\n",
       "      <td>0.396393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.711233</td>\n",
       "      <td>0.594068</td>\n",
       "      <td>0.381705</td>\n",
       "      <td>0.354922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.921572</td>\n",
       "      <td>0.922506</td>\n",
       "      <td>0.627632</td>\n",
       "      <td>0.714347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.771748</td>\n",
       "      <td>0.79944</td>\n",
       "      <td>0.682897</td>\n",
       "      <td>0.714125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.93563</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.799539</td>\n",
       "      <td>0.784586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.964526</td>\n",
       "      <td>0.957153</td>\n",
       "      <td>0.877073</td>\n",
       "      <td>0.853139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.870195</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>0.227838</td>\n",
       "      <td>0.25137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.924402</td>\n",
       "      <td>0.909954</td>\n",
       "      <td>0.396198</td>\n",
       "      <td>0.434953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.845016</td>\n",
       "      <td>0.817591</td>\n",
       "      <td>0.593726</td>\n",
       "      <td>0.610168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.91091</td>\n",
       "      <td>0.924609</td>\n",
       "      <td>0.206926</td>\n",
       "      <td>0.25669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.900727</td>\n",
       "      <td>0.907683</td>\n",
       "      <td>0.568995</td>\n",
       "      <td>0.609846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.947501</td>\n",
       "      <td>0.952309</td>\n",
       "      <td>0.245754</td>\n",
       "      <td>0.338065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.848663</td>\n",
       "      <td>0.895498</td>\n",
       "      <td>0.72579</td>\n",
       "      <td>0.839846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.893009</td>\n",
       "      <td>0.883966</td>\n",
       "      <td>0.569737</td>\n",
       "      <td>0.560389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.989614</td>\n",
       "      <td>0.993197</td>\n",
       "      <td>0.876251</td>\n",
       "      <td>0.91728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.736684</td>\n",
       "      <td>0.775493</td>\n",
       "      <td>0.159855</td>\n",
       "      <td>0.215551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.874213</td>\n",
       "      <td>0.867676</td>\n",
       "      <td>0.659973</td>\n",
       "      <td>0.712485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.900476</td>\n",
       "      <td>0.913253</td>\n",
       "      <td>0.800334</td>\n",
       "      <td>0.83174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.871732</td>\n",
       "      <td>0.875498</td>\n",
       "      <td>0.826451</td>\n",
       "      <td>0.793873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.94609</td>\n",
       "      <td>0.942254</td>\n",
       "      <td>0.727406</td>\n",
       "      <td>0.69323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.897848</td>\n",
       "      <td>0.917151</td>\n",
       "      <td>0.791018</td>\n",
       "      <td>0.842429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.693046</td>\n",
       "      <td>0.68976</td>\n",
       "      <td>0.376076</td>\n",
       "      <td>0.452604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.81412</td>\n",
       "      <td>0.875691</td>\n",
       "      <td>0.605209</td>\n",
       "      <td>0.695838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.936276</td>\n",
       "      <td>0.944919</td>\n",
       "      <td>0.853335</td>\n",
       "      <td>0.889483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.774405</td>\n",
       "      <td>0.777926</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.859906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.788306</td>\n",
       "      <td>0.788255</td>\n",
       "      <td>0.457273</td>\n",
       "      <td>0.503626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.682268</td>\n",
       "      <td>0.681457</td>\n",
       "      <td>0.512628</td>\n",
       "      <td>0.568467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.987666</td>\n",
       "      <td>0.986618</td>\n",
       "      <td>0.746052</td>\n",
       "      <td>0.739512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.827151</td>\n",
       "      <td>0.810905</td>\n",
       "      <td>0.566046</td>\n",
       "      <td>0.603057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.775378</td>\n",
       "      <td>0.78278</td>\n",
       "      <td>0.562725</td>\n",
       "      <td>0.601574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.976376</td>\n",
       "      <td>0.982265</td>\n",
       "      <td>0.705687</td>\n",
       "      <td>0.821371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.836905</td>\n",
       "      <td>0.851008</td>\n",
       "      <td>0.675152</td>\n",
       "      <td>0.708974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.852789</td>\n",
       "      <td>0.824869</td>\n",
       "      <td>0.258481</td>\n",
       "      <td>0.272229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.962611</td>\n",
       "      <td>0.958374</td>\n",
       "      <td>0.727037</td>\n",
       "      <td>0.717814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.639579</td>\n",
       "      <td>0.575622</td>\n",
       "      <td>0.409339</td>\n",
       "      <td>0.462609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.440434</td>\n",
       "      <td>0.44937</td>\n",
       "      <td>0.295664</td>\n",
       "      <td>0.327829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.555231</td>\n",
       "      <td>0.650843</td>\n",
       "      <td>0.427922</td>\n",
       "      <td>0.518288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.811663</td>\n",
       "      <td>0.813221</td>\n",
       "      <td>0.70019</td>\n",
       "      <td>0.731955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.793554</td>\n",
       "      <td>0.809774</td>\n",
       "      <td>0.648898</td>\n",
       "      <td>0.692236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.883391</td>\n",
       "      <td>0.87248</td>\n",
       "      <td>0.591813</td>\n",
       "      <td>0.624337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.853086</td>\n",
       "      <td>0.844039</td>\n",
       "      <td>0.654879</td>\n",
       "      <td>0.694241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.087763</td>\n",
       "      <td>0.442129</td>\n",
       "      <td>0.451125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.866034</td>\n",
       "      <td>0.869253</td>\n",
       "      <td>0.402732</td>\n",
       "      <td>0.412912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  we save your browsing history  \\\n",
       "Privacy Policy                                    \n",
       "Google                                 0.844826   \n",
       "Aws                                    0.906165   \n",
       "AliExpress                             0.737969   \n",
       "Meta                                   0.946151   \n",
       "TikTok                                 0.778982   \n",
       "YouTube                                0.896308   \n",
       "Waze                                   0.728593   \n",
       "Wix                                    0.711233   \n",
       "Bookings                               0.921572   \n",
       "whatsapp                               0.771748   \n",
       "apple                                   0.93563   \n",
       "wolt                                   0.964526   \n",
       "Visa                                   0.870195   \n",
       "Mastercard                             0.924402   \n",
       "AirBNB                                 0.845016   \n",
       "uber                                    0.91091   \n",
       "Spotify                                0.900727   \n",
       "samsung                                0.947501   \n",
       "Wordpress                              0.848663   \n",
       "instagram                              0.893009   \n",
       "MacDonalds                             0.989614   \n",
       "FDA                                    0.736684   \n",
       "Oracle                                 0.874213   \n",
       "Zara                                   0.900476   \n",
       "cocacola                               0.871732   \n",
       "Xiaomi                                  0.94609   \n",
       "Nasdaq                                 0.897848   \n",
       "Walmart                                0.693046   \n",
       "AirCanada                               0.81412   \n",
       "Lufthansa                              0.936276   \n",
       "shopify                                0.774405   \n",
       "Netflix                                0.788306   \n",
       "adobe                                  0.682268   \n",
       "Starbucks                              0.987666   \n",
       "Shoppers                               0.827151   \n",
       "Decathlon                              0.775378   \n",
       "waltdisney                             0.976376   \n",
       "AmericanEagle                          0.836905   \n",
       "lululemon                              0.852789   \n",
       "SAP                                    0.962611   \n",
       "JetBrains                              0.639579   \n",
       "MySQLCode                              0.440434   \n",
       "Cadens                                 0.555231   \n",
       "EpicGames                              0.811663   \n",
       "unitedHealthGroup                      0.793554   \n",
       "Slack                                  0.883391   \n",
       "SalesForce                             0.853086   \n",
       "JPMorgan                               0.135747   \n",
       "JohnsonAndJohnson                      0.866034   \n",
       "\n",
       "                  we save your browsing preferences  \\\n",
       "Privacy Policy                                        \n",
       "Google                                     0.886259   \n",
       "Aws                                        0.908969   \n",
       "AliExpress                                 0.682618   \n",
       "Meta                                       0.931737   \n",
       "TikTok                                     0.816761   \n",
       "YouTube                                    0.897105   \n",
       "Waze                                       0.781011   \n",
       "Wix                                        0.594068   \n",
       "Bookings                                   0.922506   \n",
       "whatsapp                                    0.79944   \n",
       "apple                                      0.932991   \n",
       "wolt                                       0.957153   \n",
       "Visa                                       0.877574   \n",
       "Mastercard                                 0.909954   \n",
       "AirBNB                                     0.817591   \n",
       "uber                                       0.924609   \n",
       "Spotify                                    0.907683   \n",
       "samsung                                    0.952309   \n",
       "Wordpress                                  0.895498   \n",
       "instagram                                  0.883966   \n",
       "MacDonalds                                 0.993197   \n",
       "FDA                                        0.775493   \n",
       "Oracle                                     0.867676   \n",
       "Zara                                       0.913253   \n",
       "cocacola                                   0.875498   \n",
       "Xiaomi                                     0.942254   \n",
       "Nasdaq                                     0.917151   \n",
       "Walmart                                     0.68976   \n",
       "AirCanada                                  0.875691   \n",
       "Lufthansa                                  0.944919   \n",
       "shopify                                    0.777926   \n",
       "Netflix                                    0.788255   \n",
       "adobe                                      0.681457   \n",
       "Starbucks                                  0.986618   \n",
       "Shoppers                                   0.810905   \n",
       "Decathlon                                   0.78278   \n",
       "waltdisney                                 0.982265   \n",
       "AmericanEagle                              0.851008   \n",
       "lululemon                                  0.824869   \n",
       "SAP                                        0.958374   \n",
       "JetBrains                                  0.575622   \n",
       "MySQLCode                                   0.44937   \n",
       "Cadens                                     0.650843   \n",
       "EpicGames                                  0.813221   \n",
       "unitedHealthGroup                          0.809774   \n",
       "Slack                                       0.87248   \n",
       "SalesForce                                 0.844039   \n",
       "JPMorgan                                   0.087763   \n",
       "JohnsonAndJohnson                          0.869253   \n",
       "\n",
       "                  we are not collect your browsing history  \\\n",
       "Privacy Policy                                               \n",
       "Google                                            0.385589   \n",
       "Aws                                               0.805677   \n",
       "AliExpress                                        0.179964   \n",
       "Meta                                               0.91018   \n",
       "TikTok                                            0.645819   \n",
       "YouTube                                           0.481192   \n",
       "Waze                                              0.325879   \n",
       "Wix                                               0.381705   \n",
       "Bookings                                          0.627632   \n",
       "whatsapp                                          0.682897   \n",
       "apple                                             0.799539   \n",
       "wolt                                              0.877073   \n",
       "Visa                                              0.227838   \n",
       "Mastercard                                        0.396198   \n",
       "AirBNB                                            0.593726   \n",
       "uber                                              0.206926   \n",
       "Spotify                                           0.568995   \n",
       "samsung                                           0.245754   \n",
       "Wordpress                                          0.72579   \n",
       "instagram                                         0.569737   \n",
       "MacDonalds                                        0.876251   \n",
       "FDA                                               0.159855   \n",
       "Oracle                                            0.659973   \n",
       "Zara                                              0.800334   \n",
       "cocacola                                          0.826451   \n",
       "Xiaomi                                            0.727406   \n",
       "Nasdaq                                            0.791018   \n",
       "Walmart                                           0.376076   \n",
       "AirCanada                                         0.605209   \n",
       "Lufthansa                                         0.853335   \n",
       "shopify                                           0.828629   \n",
       "Netflix                                           0.457273   \n",
       "adobe                                             0.512628   \n",
       "Starbucks                                         0.746052   \n",
       "Shoppers                                          0.566046   \n",
       "Decathlon                                         0.562725   \n",
       "waltdisney                                        0.705687   \n",
       "AmericanEagle                                     0.675152   \n",
       "lululemon                                         0.258481   \n",
       "SAP                                               0.727037   \n",
       "JetBrains                                         0.409339   \n",
       "MySQLCode                                         0.295664   \n",
       "Cadens                                            0.427922   \n",
       "EpicGames                                          0.70019   \n",
       "unitedHealthGroup                                 0.648898   \n",
       "Slack                                             0.591813   \n",
       "SalesForce                                        0.654879   \n",
       "JPMorgan                                          0.442129   \n",
       "JohnsonAndJohnson                                 0.402732   \n",
       "\n",
       "                  we are not collect your browsing preferences  \n",
       "Privacy Policy                                                  \n",
       "Google                                                0.591475  \n",
       "Aws                                                   0.818994  \n",
       "AliExpress                                            0.166785  \n",
       "Meta                                                   0.89538  \n",
       "TikTok                                                0.690651  \n",
       "YouTube                                               0.497081  \n",
       "Waze                                                  0.396393  \n",
       "Wix                                                   0.354922  \n",
       "Bookings                                              0.714347  \n",
       "whatsapp                                              0.714125  \n",
       "apple                                                 0.784586  \n",
       "wolt                                                  0.853139  \n",
       "Visa                                                   0.25137  \n",
       "Mastercard                                            0.434953  \n",
       "AirBNB                                                0.610168  \n",
       "uber                                                   0.25669  \n",
       "Spotify                                               0.609846  \n",
       "samsung                                               0.338065  \n",
       "Wordpress                                             0.839846  \n",
       "instagram                                             0.560389  \n",
       "MacDonalds                                             0.91728  \n",
       "FDA                                                   0.215551  \n",
       "Oracle                                                0.712485  \n",
       "Zara                                                   0.83174  \n",
       "cocacola                                              0.793873  \n",
       "Xiaomi                                                 0.69323  \n",
       "Nasdaq                                                0.842429  \n",
       "Walmart                                               0.452604  \n",
       "AirCanada                                             0.695838  \n",
       "Lufthansa                                             0.889483  \n",
       "shopify                                               0.859906  \n",
       "Netflix                                               0.503626  \n",
       "adobe                                                 0.568467  \n",
       "Starbucks                                             0.739512  \n",
       "Shoppers                                              0.603057  \n",
       "Decathlon                                             0.601574  \n",
       "waltdisney                                            0.821371  \n",
       "AmericanEagle                                         0.708974  \n",
       "lululemon                                             0.272229  \n",
       "SAP                                                   0.717814  \n",
       "JetBrains                                             0.462609  \n",
       "MySQLCode                                             0.327829  \n",
       "Cadens                                                0.518288  \n",
       "EpicGames                                             0.731955  \n",
       "unitedHealthGroup                                     0.692236  \n",
       "Slack                                                 0.624337  \n",
       "SalesForce                                            0.694241  \n",
       "JPMorgan                                              0.451125  \n",
       "JohnsonAndJohnson                                     0.412912  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data_security Matrix - _browser [3]:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'we save your browsing history'\n",
    "           ,'we save your browsing preferences'\n",
    "           ,'we are not collect your browsing history'\n",
    "           ,'we are not collect your browsing preferences']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_ML_browser = pd.DataFrame(columns = Phrases)\n",
    "matrix_data_collection_ML_browser['Privacy Policy'] = websites\n",
    "matrix_data_collection_ML_browser.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_collection_ML_browser:\n",
    "        matrix_data_collection_ML_browser.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "    \n",
    "matrix_data_collection_ML_browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3099526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [1 1 1 1 0 1 1 0 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.50      0.43      0.46        15\n",
      "weighted avg       1.00      0.87      0.93        15\n",
      "\n",
      "Random Forest Classifaier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "Logistic Reg Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "SVM Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "KNN Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "neural_network Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_data_collection_ML_browser.iloc[:35,:] \n",
    "X_test = matrix_data_collection_ML_browser.iloc[34:,:]\n",
    "y_train = data_collection_train_browser[:35]\n",
    "y_test = data_collection_train_browser[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "##Logistic Reg Classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "print('Logistic Reg Classifier:', pred_clf)\n",
    "print(classification_report(y_test, pred_clf))\n",
    "\n",
    "##SVM\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM = SVM.fit(X_train, y_train)\n",
    "pred_SVM = SVM.predict(X_test)\n",
    "print('SVM Classifier:', pred_SVM)\n",
    "print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN Classifier:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network Classifier:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3d8c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_browser = pred_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cac49178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>we save your recording</th>\n",
       "      <th>we save your audio</th>\n",
       "      <th>we are collecting your voice messages</th>\n",
       "      <th>we are not collect your audio and recording</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.941591</td>\n",
       "      <td>0.960918</td>\n",
       "      <td>0.94851</td>\n",
       "      <td>0.280658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.909562</td>\n",
       "      <td>0.875818</td>\n",
       "      <td>0.824499</td>\n",
       "      <td>0.681671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.784952</td>\n",
       "      <td>0.737044</td>\n",
       "      <td>0.642609</td>\n",
       "      <td>0.208739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.973421</td>\n",
       "      <td>0.93645</td>\n",
       "      <td>0.850466</td>\n",
       "      <td>0.809944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.881189</td>\n",
       "      <td>0.836365</td>\n",
       "      <td>0.731347</td>\n",
       "      <td>0.427886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.93815</td>\n",
       "      <td>0.924631</td>\n",
       "      <td>0.907074</td>\n",
       "      <td>0.19376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.868342</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.559361</td>\n",
       "      <td>0.200665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.807548</td>\n",
       "      <td>0.85433</td>\n",
       "      <td>0.893022</td>\n",
       "      <td>0.336657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.926708</td>\n",
       "      <td>0.939017</td>\n",
       "      <td>0.948596</td>\n",
       "      <td>0.308483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.737847</td>\n",
       "      <td>0.700788</td>\n",
       "      <td>0.648564</td>\n",
       "      <td>0.378764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.938227</td>\n",
       "      <td>0.949649</td>\n",
       "      <td>0.955192</td>\n",
       "      <td>0.620912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.971793</td>\n",
       "      <td>0.979311</td>\n",
       "      <td>0.936459</td>\n",
       "      <td>0.78439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.897844</td>\n",
       "      <td>0.883556</td>\n",
       "      <td>0.907582</td>\n",
       "      <td>0.270371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.967215</td>\n",
       "      <td>0.953819</td>\n",
       "      <td>0.34663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.912181</td>\n",
       "      <td>0.895924</td>\n",
       "      <td>0.93349</td>\n",
       "      <td>0.614539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.935751</td>\n",
       "      <td>0.935663</td>\n",
       "      <td>0.927015</td>\n",
       "      <td>0.328322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.958154</td>\n",
       "      <td>0.90445</td>\n",
       "      <td>0.833109</td>\n",
       "      <td>0.297406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.941112</td>\n",
       "      <td>0.922043</td>\n",
       "      <td>0.935532</td>\n",
       "      <td>0.184835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.893265</td>\n",
       "      <td>0.898953</td>\n",
       "      <td>0.910948</td>\n",
       "      <td>0.699557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.93141</td>\n",
       "      <td>0.89867</td>\n",
       "      <td>0.893929</td>\n",
       "      <td>0.448192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.992387</td>\n",
       "      <td>0.993309</td>\n",
       "      <td>0.992879</td>\n",
       "      <td>0.851104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.820216</td>\n",
       "      <td>0.706126</td>\n",
       "      <td>0.594205</td>\n",
       "      <td>0.107948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.913514</td>\n",
       "      <td>0.921733</td>\n",
       "      <td>0.939403</td>\n",
       "      <td>0.4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.903139</td>\n",
       "      <td>0.891573</td>\n",
       "      <td>0.905741</td>\n",
       "      <td>0.647264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.906922</td>\n",
       "      <td>0.89464</td>\n",
       "      <td>0.869038</td>\n",
       "      <td>0.66902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.951037</td>\n",
       "      <td>0.94525</td>\n",
       "      <td>0.924803</td>\n",
       "      <td>0.624591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.912052</td>\n",
       "      <td>0.893886</td>\n",
       "      <td>0.926942</td>\n",
       "      <td>0.689271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.856032</td>\n",
       "      <td>0.827532</td>\n",
       "      <td>0.839811</td>\n",
       "      <td>0.325638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.952052</td>\n",
       "      <td>0.958508</td>\n",
       "      <td>0.919502</td>\n",
       "      <td>0.418419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.964292</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.939165</td>\n",
       "      <td>0.763726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.867199</td>\n",
       "      <td>0.913469</td>\n",
       "      <td>0.80532</td>\n",
       "      <td>0.830089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.851676</td>\n",
       "      <td>0.859429</td>\n",
       "      <td>0.916745</td>\n",
       "      <td>0.175619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.824112</td>\n",
       "      <td>0.818703</td>\n",
       "      <td>0.770192</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.985573</td>\n",
       "      <td>0.982822</td>\n",
       "      <td>0.984652</td>\n",
       "      <td>0.777005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.860931</td>\n",
       "      <td>0.899887</td>\n",
       "      <td>0.893493</td>\n",
       "      <td>0.450582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.880501</td>\n",
       "      <td>0.878408</td>\n",
       "      <td>0.725812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.983204</td>\n",
       "      <td>0.977924</td>\n",
       "      <td>0.975217</td>\n",
       "      <td>0.845688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.896993</td>\n",
       "      <td>0.890474</td>\n",
       "      <td>0.947897</td>\n",
       "      <td>0.593181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.941323</td>\n",
       "      <td>0.920482</td>\n",
       "      <td>0.945416</td>\n",
       "      <td>0.238647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.976725</td>\n",
       "      <td>0.972788</td>\n",
       "      <td>0.974705</td>\n",
       "      <td>0.636963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.812333</td>\n",
       "      <td>0.811546</td>\n",
       "      <td>0.872717</td>\n",
       "      <td>0.366604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.584312</td>\n",
       "      <td>0.631464</td>\n",
       "      <td>0.670436</td>\n",
       "      <td>0.122278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.77475</td>\n",
       "      <td>0.586624</td>\n",
       "      <td>0.473729</td>\n",
       "      <td>0.08796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.888175</td>\n",
       "      <td>0.874685</td>\n",
       "      <td>0.93418</td>\n",
       "      <td>0.515288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.837128</td>\n",
       "      <td>0.768445</td>\n",
       "      <td>0.786347</td>\n",
       "      <td>0.406447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.935279</td>\n",
       "      <td>0.902621</td>\n",
       "      <td>0.904287</td>\n",
       "      <td>0.449557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.914576</td>\n",
       "      <td>0.857858</td>\n",
       "      <td>0.944275</td>\n",
       "      <td>0.688217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.343925</td>\n",
       "      <td>0.314765</td>\n",
       "      <td>0.93929</td>\n",
       "      <td>0.271497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.903741</td>\n",
       "      <td>0.911422</td>\n",
       "      <td>0.886837</td>\n",
       "      <td>0.313857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  we save your recording we save your audio  \\\n",
       "Privacy Policy                                                \n",
       "Google                          0.941591           0.960918   \n",
       "Aws                             0.909562           0.875818   \n",
       "AliExpress                      0.784952           0.737044   \n",
       "Meta                            0.973421            0.93645   \n",
       "TikTok                          0.881189           0.836365   \n",
       "YouTube                          0.93815           0.924631   \n",
       "Waze                            0.868342           0.841272   \n",
       "Wix                             0.807548            0.85433   \n",
       "Bookings                        0.926708           0.939017   \n",
       "whatsapp                        0.737847           0.700788   \n",
       "apple                           0.938227           0.949649   \n",
       "wolt                            0.971793           0.979311   \n",
       "Visa                            0.897844           0.883556   \n",
       "Mastercard                      0.954545           0.967215   \n",
       "AirBNB                          0.912181           0.895924   \n",
       "uber                            0.935751           0.935663   \n",
       "Spotify                         0.958154            0.90445   \n",
       "samsung                         0.941112           0.922043   \n",
       "Wordpress                       0.893265           0.898953   \n",
       "instagram                        0.93141            0.89867   \n",
       "MacDonalds                      0.992387           0.993309   \n",
       "FDA                             0.820216           0.706126   \n",
       "Oracle                          0.913514           0.921733   \n",
       "Zara                            0.903139           0.891573   \n",
       "cocacola                        0.906922            0.89464   \n",
       "Xiaomi                          0.951037            0.94525   \n",
       "Nasdaq                          0.912052           0.893886   \n",
       "Walmart                         0.856032           0.827532   \n",
       "AirCanada                       0.952052           0.958508   \n",
       "Lufthansa                       0.964292             0.9622   \n",
       "shopify                         0.867199           0.913469   \n",
       "Netflix                         0.851676           0.859429   \n",
       "adobe                           0.824112           0.818703   \n",
       "Starbucks                       0.985573           0.982822   \n",
       "Shoppers                        0.860931           0.899887   \n",
       "Decathlon                          0.858           0.880501   \n",
       "waltdisney                      0.983204           0.977924   \n",
       "AmericanEagle                   0.896993           0.890474   \n",
       "lululemon                       0.941323           0.920482   \n",
       "SAP                             0.976725           0.972788   \n",
       "JetBrains                       0.812333           0.811546   \n",
       "MySQLCode                       0.584312           0.631464   \n",
       "Cadens                           0.77475           0.586624   \n",
       "EpicGames                       0.888175           0.874685   \n",
       "unitedHealthGroup               0.837128           0.768445   \n",
       "Slack                           0.935279           0.902621   \n",
       "SalesForce                      0.914576           0.857858   \n",
       "JPMorgan                        0.343925           0.314765   \n",
       "JohnsonAndJohnson               0.903741           0.911422   \n",
       "\n",
       "                  we are collecting your voice messages  \\\n",
       "Privacy Policy                                            \n",
       "Google                                          0.94851   \n",
       "Aws                                            0.824499   \n",
       "AliExpress                                     0.642609   \n",
       "Meta                                           0.850466   \n",
       "TikTok                                         0.731347   \n",
       "YouTube                                        0.907074   \n",
       "Waze                                           0.559361   \n",
       "Wix                                            0.893022   \n",
       "Bookings                                       0.948596   \n",
       "whatsapp                                       0.648564   \n",
       "apple                                          0.955192   \n",
       "wolt                                           0.936459   \n",
       "Visa                                           0.907582   \n",
       "Mastercard                                     0.953819   \n",
       "AirBNB                                          0.93349   \n",
       "uber                                           0.927015   \n",
       "Spotify                                        0.833109   \n",
       "samsung                                        0.935532   \n",
       "Wordpress                                      0.910948   \n",
       "instagram                                      0.893929   \n",
       "MacDonalds                                     0.992879   \n",
       "FDA                                            0.594205   \n",
       "Oracle                                         0.939403   \n",
       "Zara                                           0.905741   \n",
       "cocacola                                       0.869038   \n",
       "Xiaomi                                         0.924803   \n",
       "Nasdaq                                         0.926942   \n",
       "Walmart                                        0.839811   \n",
       "AirCanada                                      0.919502   \n",
       "Lufthansa                                      0.939165   \n",
       "shopify                                         0.80532   \n",
       "Netflix                                        0.916745   \n",
       "adobe                                          0.770192   \n",
       "Starbucks                                      0.984652   \n",
       "Shoppers                                       0.893493   \n",
       "Decathlon                                      0.878408   \n",
       "waltdisney                                     0.975217   \n",
       "AmericanEagle                                  0.947897   \n",
       "lululemon                                      0.945416   \n",
       "SAP                                            0.974705   \n",
       "JetBrains                                      0.872717   \n",
       "MySQLCode                                      0.670436   \n",
       "Cadens                                         0.473729   \n",
       "EpicGames                                       0.93418   \n",
       "unitedHealthGroup                              0.786347   \n",
       "Slack                                          0.904287   \n",
       "SalesForce                                     0.944275   \n",
       "JPMorgan                                        0.93929   \n",
       "JohnsonAndJohnson                              0.886837   \n",
       "\n",
       "                  we are not collect your audio and recording  \n",
       "Privacy Policy                                                 \n",
       "Google                                               0.280658  \n",
       "Aws                                                  0.681671  \n",
       "AliExpress                                           0.208739  \n",
       "Meta                                                 0.809944  \n",
       "TikTok                                               0.427886  \n",
       "YouTube                                               0.19376  \n",
       "Waze                                                 0.200665  \n",
       "Wix                                                  0.336657  \n",
       "Bookings                                             0.308483  \n",
       "whatsapp                                             0.378764  \n",
       "apple                                                0.620912  \n",
       "wolt                                                  0.78439  \n",
       "Visa                                                 0.270371  \n",
       "Mastercard                                            0.34663  \n",
       "AirBNB                                               0.614539  \n",
       "uber                                                 0.328322  \n",
       "Spotify                                              0.297406  \n",
       "samsung                                              0.184835  \n",
       "Wordpress                                            0.699557  \n",
       "instagram                                            0.448192  \n",
       "MacDonalds                                           0.851104  \n",
       "FDA                                                  0.107948  \n",
       "Oracle                                                 0.4855  \n",
       "Zara                                                 0.647264  \n",
       "cocacola                                              0.66902  \n",
       "Xiaomi                                               0.624591  \n",
       "Nasdaq                                               0.689271  \n",
       "Walmart                                              0.325638  \n",
       "AirCanada                                            0.418419  \n",
       "Lufthansa                                            0.763726  \n",
       "shopify                                              0.830089  \n",
       "Netflix                                              0.175619  \n",
       "adobe                                                   0.404  \n",
       "Starbucks                                            0.777005  \n",
       "Shoppers                                             0.450582  \n",
       "Decathlon                                            0.725812  \n",
       "waltdisney                                           0.845688  \n",
       "AmericanEagle                                        0.593181  \n",
       "lululemon                                            0.238647  \n",
       "SAP                                                  0.636963  \n",
       "JetBrains                                            0.366604  \n",
       "MySQLCode                                            0.122278  \n",
       "Cadens                                                0.08796  \n",
       "EpicGames                                            0.515288  \n",
       "unitedHealthGroup                                    0.406447  \n",
       "Slack                                                0.449557  \n",
       "SalesForce                                           0.688217  \n",
       "JPMorgan                                             0.271497  \n",
       "JohnsonAndJohnson                                    0.313857  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data_security Matrix - data_collection_train_voice [4]:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'we save your recording'\n",
    "           ,'we save your audio'\n",
    "           ,'we are collecting your voice messages'\n",
    "           ,'we are not collect your audio and recording']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_ML_voice = pd.DataFrame(columns = Phrases)\n",
    "matrix_data_collection_ML_voice['Privacy Policy'] = websites\n",
    "matrix_data_collection_ML_voice.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_collection_ML_voice:\n",
    "        matrix_data_collection_ML_voice.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "    \n",
    "matrix_data_collection_ML_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dd8059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [1 0 0 0 1 0 0 1 1 1 0 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.44      0.53         9\n",
      "           1       0.44      0.67      0.53         6\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.56      0.56      0.53        15\n",
      "weighted avg       0.58      0.53      0.53        15\n",
      "\n",
      "Random Forest Classifaier: [1 0 0 0 1 0 0 1 0 1 0 0 1 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78         9\n",
      "           1       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.72      0.72      0.72        15\n",
      "weighted avg       0.73      0.73      0.73        15\n",
      "\n",
      "Logistic Reg Classifier: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         9\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.30      0.50      0.37        15\n",
      "weighted avg       0.36      0.60      0.45        15\n",
      "\n",
      "SVM Classifier: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75         9\n",
      "           1       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.30      0.50      0.37        15\n",
      "weighted avg       0.36      0.60      0.45        15\n",
      "\n",
      "KNN Classifier: [0 0 0 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.89      0.73         9\n",
      "           1       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.60        15\n",
      "   macro avg       0.56      0.53      0.49        15\n",
      "weighted avg       0.57      0.60      0.54        15\n",
      "\n",
      "neural_network Classifier: [0 0 0 0 1 0 0 1 1 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.67         9\n",
      "           1       0.33      0.17      0.22         6\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.46      0.47      0.44        15\n",
      "weighted avg       0.48      0.53      0.49        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_data_collection_ML_voice.iloc[:35,:] \n",
    "X_test = matrix_data_collection_ML_voice.iloc[34:,:]\n",
    "y_train = data_collection_train_voice[:35]\n",
    "y_test = data_collection_train_voice[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "##Logistic Reg Classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "print('Logistic Reg Classifier:', pred_clf)\n",
    "print(classification_report(y_test, pred_clf))\n",
    "\n",
    "##SVM\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM = SVM.fit(X_train, y_train)\n",
    "pred_SVM = SVM.predict(X_test)\n",
    "print('SVM Classifier:', pred_SVM)\n",
    "print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN Classifier:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network Classifier:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb91b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_voice = pred_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cce472b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>we save your payments data</th>\n",
       "      <th>we collect your payments details</th>\n",
       "      <th>we are not collect your payments data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.760889</td>\n",
       "      <td>0.957064</td>\n",
       "      <td>0.35989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.863534</td>\n",
       "      <td>0.94285</td>\n",
       "      <td>0.681946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.620869</td>\n",
       "      <td>0.756453</td>\n",
       "      <td>0.14762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.904471</td>\n",
       "      <td>0.946495</td>\n",
       "      <td>0.763563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.719862</td>\n",
       "      <td>0.762308</td>\n",
       "      <td>0.519818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.832188</td>\n",
       "      <td>0.899888</td>\n",
       "      <td>0.362435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.629844</td>\n",
       "      <td>0.78542</td>\n",
       "      <td>0.200484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.565954</td>\n",
       "      <td>0.901089</td>\n",
       "      <td>0.219454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.937423</td>\n",
       "      <td>0.985275</td>\n",
       "      <td>0.739429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.607673</td>\n",
       "      <td>0.626408</td>\n",
       "      <td>0.468319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.906682</td>\n",
       "      <td>0.948844</td>\n",
       "      <td>0.677212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.982121</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>0.945865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.874818</td>\n",
       "      <td>0.905988</td>\n",
       "      <td>0.222538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.881218</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.351764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.839174</td>\n",
       "      <td>0.91905</td>\n",
       "      <td>0.542553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.890093</td>\n",
       "      <td>0.964105</td>\n",
       "      <td>0.151381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.817087</td>\n",
       "      <td>0.898992</td>\n",
       "      <td>0.377196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.920234</td>\n",
       "      <td>0.975735</td>\n",
       "      <td>0.168954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.749894</td>\n",
       "      <td>0.882585</td>\n",
       "      <td>0.483164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.855557</td>\n",
       "      <td>0.918676</td>\n",
       "      <td>0.479391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.994596</td>\n",
       "      <td>0.997426</td>\n",
       "      <td>0.925925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.604785</td>\n",
       "      <td>0.794802</td>\n",
       "      <td>0.081816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.826418</td>\n",
       "      <td>0.911395</td>\n",
       "      <td>0.572373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.866745</td>\n",
       "      <td>0.944955</td>\n",
       "      <td>0.685619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.833735</td>\n",
       "      <td>0.954852</td>\n",
       "      <td>0.687416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.938553</td>\n",
       "      <td>0.956789</td>\n",
       "      <td>0.678593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.859412</td>\n",
       "      <td>0.898129</td>\n",
       "      <td>0.718392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.690437</td>\n",
       "      <td>0.910869</td>\n",
       "      <td>0.384419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.859073</td>\n",
       "      <td>0.954266</td>\n",
       "      <td>0.540701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.920324</td>\n",
       "      <td>0.919252</td>\n",
       "      <td>0.836549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.735863</td>\n",
       "      <td>0.927163</td>\n",
       "      <td>0.868976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.787734</td>\n",
       "      <td>0.944674</td>\n",
       "      <td>0.388236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.622397</td>\n",
       "      <td>0.800092</td>\n",
       "      <td>0.452677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.963151</td>\n",
       "      <td>0.978108</td>\n",
       "      <td>0.464495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.787755</td>\n",
       "      <td>0.910375</td>\n",
       "      <td>0.461409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.820564</td>\n",
       "      <td>0.920285</td>\n",
       "      <td>0.62281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.979976</td>\n",
       "      <td>0.991291</td>\n",
       "      <td>0.798566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.836469</td>\n",
       "      <td>0.915344</td>\n",
       "      <td>0.646187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.914029</td>\n",
       "      <td>0.982425</td>\n",
       "      <td>0.375253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.973517</td>\n",
       "      <td>0.985963</td>\n",
       "      <td>0.782157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.668923</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>0.325917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.239928</td>\n",
       "      <td>0.328202</td>\n",
       "      <td>0.109084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.5415</td>\n",
       "      <td>0.701849</td>\n",
       "      <td>0.402434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.780439</td>\n",
       "      <td>0.953871</td>\n",
       "      <td>0.675134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.710373</td>\n",
       "      <td>0.834864</td>\n",
       "      <td>0.524795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.875689</td>\n",
       "      <td>0.943258</td>\n",
       "      <td>0.624575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.84033</td>\n",
       "      <td>0.933479</td>\n",
       "      <td>0.646936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.123821</td>\n",
       "      <td>0.258796</td>\n",
       "      <td>0.375186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.847181</td>\n",
       "      <td>0.947714</td>\n",
       "      <td>0.303934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  we save your payments data we collect your payments details  \\\n",
       "Privacy Policy                                                                  \n",
       "Google                              0.760889                         0.957064   \n",
       "Aws                                 0.863534                          0.94285   \n",
       "AliExpress                          0.620869                         0.756453   \n",
       "Meta                                0.904471                         0.946495   \n",
       "TikTok                              0.719862                         0.762308   \n",
       "YouTube                             0.832188                         0.899888   \n",
       "Waze                                0.629844                          0.78542   \n",
       "Wix                                 0.565954                         0.901089   \n",
       "Bookings                            0.937423                         0.985275   \n",
       "whatsapp                            0.607673                         0.626408   \n",
       "apple                               0.906682                         0.948844   \n",
       "wolt                                0.982121                           0.9951   \n",
       "Visa                                0.874818                         0.905988   \n",
       "Mastercard                          0.881218                         0.953341   \n",
       "AirBNB                              0.839174                          0.91905   \n",
       "uber                                0.890093                         0.964105   \n",
       "Spotify                             0.817087                         0.898992   \n",
       "samsung                             0.920234                         0.975735   \n",
       "Wordpress                           0.749894                         0.882585   \n",
       "instagram                           0.855557                         0.918676   \n",
       "MacDonalds                          0.994596                         0.997426   \n",
       "FDA                                 0.604785                         0.794802   \n",
       "Oracle                              0.826418                         0.911395   \n",
       "Zara                                0.866745                         0.944955   \n",
       "cocacola                            0.833735                         0.954852   \n",
       "Xiaomi                              0.938553                         0.956789   \n",
       "Nasdaq                              0.859412                         0.898129   \n",
       "Walmart                             0.690437                         0.910869   \n",
       "AirCanada                           0.859073                         0.954266   \n",
       "Lufthansa                           0.920324                         0.919252   \n",
       "shopify                             0.735863                         0.927163   \n",
       "Netflix                             0.787734                         0.944674   \n",
       "adobe                               0.622397                         0.800092   \n",
       "Starbucks                           0.963151                         0.978108   \n",
       "Shoppers                            0.787755                         0.910375   \n",
       "Decathlon                           0.820564                         0.920285   \n",
       "waltdisney                          0.979976                         0.991291   \n",
       "AmericanEagle                       0.836469                         0.915344   \n",
       "lululemon                           0.914029                         0.982425   \n",
       "SAP                                 0.973517                         0.985963   \n",
       "JetBrains                           0.668923                         0.852227   \n",
       "MySQLCode                           0.239928                         0.328202   \n",
       "Cadens                                0.5415                         0.701849   \n",
       "EpicGames                           0.780439                         0.953871   \n",
       "unitedHealthGroup                   0.710373                         0.834864   \n",
       "Slack                               0.875689                         0.943258   \n",
       "SalesForce                           0.84033                         0.933479   \n",
       "JPMorgan                            0.123821                         0.258796   \n",
       "JohnsonAndJohnson                   0.847181                         0.947714   \n",
       "\n",
       "                  we are not collect your payments data  \n",
       "Privacy Policy                                           \n",
       "Google                                          0.35989  \n",
       "Aws                                            0.681946  \n",
       "AliExpress                                      0.14762  \n",
       "Meta                                           0.763563  \n",
       "TikTok                                         0.519818  \n",
       "YouTube                                        0.362435  \n",
       "Waze                                           0.200484  \n",
       "Wix                                            0.219454  \n",
       "Bookings                                       0.739429  \n",
       "whatsapp                                       0.468319  \n",
       "apple                                          0.677212  \n",
       "wolt                                           0.945865  \n",
       "Visa                                           0.222538  \n",
       "Mastercard                                     0.351764  \n",
       "AirBNB                                         0.542553  \n",
       "uber                                           0.151381  \n",
       "Spotify                                        0.377196  \n",
       "samsung                                        0.168954  \n",
       "Wordpress                                      0.483164  \n",
       "instagram                                      0.479391  \n",
       "MacDonalds                                     0.925925  \n",
       "FDA                                            0.081816  \n",
       "Oracle                                         0.572373  \n",
       "Zara                                           0.685619  \n",
       "cocacola                                       0.687416  \n",
       "Xiaomi                                         0.678593  \n",
       "Nasdaq                                         0.718392  \n",
       "Walmart                                        0.384419  \n",
       "AirCanada                                      0.540701  \n",
       "Lufthansa                                      0.836549  \n",
       "shopify                                        0.868976  \n",
       "Netflix                                        0.388236  \n",
       "adobe                                          0.452677  \n",
       "Starbucks                                      0.464495  \n",
       "Shoppers                                       0.461409  \n",
       "Decathlon                                       0.62281  \n",
       "waltdisney                                     0.798566  \n",
       "AmericanEagle                                  0.646187  \n",
       "lululemon                                      0.375253  \n",
       "SAP                                            0.782157  \n",
       "JetBrains                                      0.325917  \n",
       "MySQLCode                                      0.109084  \n",
       "Cadens                                         0.402434  \n",
       "EpicGames                                      0.675134  \n",
       "unitedHealthGroup                              0.524795  \n",
       "Slack                                          0.624575  \n",
       "SalesForce                                     0.646936  \n",
       "JPMorgan                                       0.375186  \n",
       "JohnsonAndJohnson                              0.303934  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data_security Matrix - data_collection_train_payments [5]:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'we save your payments data'\n",
    "           ,'we collect your payments details'\n",
    "           ,'we are not collect your payments data']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collecting_ML_payments = pd.DataFrame(columns = Phrases)\n",
    "matrix_data_collecting_ML_payments['Privacy Policy'] = websites\n",
    "matrix_data_collecting_ML_payments.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_collecting_ML_payments:\n",
    "        matrix_data_collecting_ML_payments.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "    \n",
    "matrix_data_collecting_ML_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93928662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [1 1 1 0 1 1 1 1 1 1 1 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.33      0.29         3\n",
      "           1       0.82      0.75      0.78        12\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.53      0.54      0.53        15\n",
      "weighted avg       0.70      0.67      0.68        15\n",
      "\n",
      "Random Forest Classifaier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.79      0.92      0.85        12\n",
      "\n",
      "    accuracy                           0.73        15\n",
      "   macro avg       0.39      0.46      0.42        15\n",
      "weighted avg       0.63      0.73      0.68        15\n",
      "\n",
      "Logistic Reg Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      1.00      0.89        12\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.40      0.50      0.44        15\n",
      "weighted avg       0.64      0.80      0.71        15\n",
      "\n",
      "SVM Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      1.00      0.89        12\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.40      0.50      0.44        15\n",
      "weighted avg       0.64      0.80      0.71        15\n",
      "\n",
      "KNN Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      1.00      0.89        12\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.40      0.50      0.44        15\n",
      "weighted avg       0.64      0.80      0.71        15\n",
      "\n",
      "neural_network Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.80      1.00      0.89        12\n",
      "\n",
      "    accuracy                           0.80        15\n",
      "   macro avg       0.40      0.50      0.44        15\n",
      "weighted avg       0.64      0.80      0.71        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(matrix_policy_change, policy_change_train\n",
    "#                                                     , test_size=0.5, random_state=42)\n",
    "\n",
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_data_collecting_ML_payments.iloc[:35,:] \n",
    "X_test = matrix_data_collecting_ML_payments.iloc[34:,:]\n",
    "y_train = data_collection_train_payments[:35]\n",
    "y_test = data_collection_train_payments[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "##Logistic Reg Classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "print('Logistic Reg Classifier:', pred_clf)\n",
    "print(classification_report(y_test, pred_clf))\n",
    "\n",
    "##SVM\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM = SVM.fit(X_train, y_train)\n",
    "pred_SVM = SVM.predict(X_test)\n",
    "print('SVM Classifier:', pred_SVM)\n",
    "print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN Classifier:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network Classifier:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6233fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_payments = pred_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a781d16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>we save your location</th>\n",
       "      <th>we are not collect your location</th>\n",
       "      <th>we save your language</th>\n",
       "      <th>we are not collect your language</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.908582</td>\n",
       "      <td>0.572177</td>\n",
       "      <td>0.948124</td>\n",
       "      <td>0.699031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.910269</td>\n",
       "      <td>0.86503</td>\n",
       "      <td>0.911911</td>\n",
       "      <td>0.848358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.746214</td>\n",
       "      <td>0.27863</td>\n",
       "      <td>0.669556</td>\n",
       "      <td>0.185862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.94689</td>\n",
       "      <td>0.879795</td>\n",
       "      <td>0.957687</td>\n",
       "      <td>0.839334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.831156</td>\n",
       "      <td>0.667386</td>\n",
       "      <td>0.865321</td>\n",
       "      <td>0.673416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.893129</td>\n",
       "      <td>0.410609</td>\n",
       "      <td>0.942237</td>\n",
       "      <td>0.456291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.654738</td>\n",
       "      <td>0.873169</td>\n",
       "      <td>0.578474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.751416</td>\n",
       "      <td>0.43633</td>\n",
       "      <td>0.816262</td>\n",
       "      <td>0.628176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.90146</td>\n",
       "      <td>0.86196</td>\n",
       "      <td>0.956732</td>\n",
       "      <td>0.916293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.820761</td>\n",
       "      <td>0.822375</td>\n",
       "      <td>0.854267</td>\n",
       "      <td>0.780319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.935751</td>\n",
       "      <td>0.837597</td>\n",
       "      <td>0.957964</td>\n",
       "      <td>0.855723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.949333</td>\n",
       "      <td>0.897251</td>\n",
       "      <td>0.974049</td>\n",
       "      <td>0.940409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.871648</td>\n",
       "      <td>0.295689</td>\n",
       "      <td>0.924106</td>\n",
       "      <td>0.324497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.946313</td>\n",
       "      <td>0.578801</td>\n",
       "      <td>0.96631</td>\n",
       "      <td>0.552825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.861365</td>\n",
       "      <td>0.693184</td>\n",
       "      <td>0.891681</td>\n",
       "      <td>0.699587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.895697</td>\n",
       "      <td>0.541264</td>\n",
       "      <td>0.952608</td>\n",
       "      <td>0.654262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.930325</td>\n",
       "      <td>0.791345</td>\n",
       "      <td>0.953288</td>\n",
       "      <td>0.780447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.918832</td>\n",
       "      <td>0.611802</td>\n",
       "      <td>0.937535</td>\n",
       "      <td>0.55608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.872656</td>\n",
       "      <td>0.781054</td>\n",
       "      <td>0.934624</td>\n",
       "      <td>0.864709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.912866</td>\n",
       "      <td>0.578284</td>\n",
       "      <td>0.957693</td>\n",
       "      <td>0.675045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.989196</td>\n",
       "      <td>0.92872</td>\n",
       "      <td>0.990008</td>\n",
       "      <td>0.965182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.793556</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.779754</td>\n",
       "      <td>0.253781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.903504</td>\n",
       "      <td>0.715593</td>\n",
       "      <td>0.915205</td>\n",
       "      <td>0.695373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.863847</td>\n",
       "      <td>0.820939</td>\n",
       "      <td>0.893863</td>\n",
       "      <td>0.774748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.909196</td>\n",
       "      <td>0.837149</td>\n",
       "      <td>0.915344</td>\n",
       "      <td>0.78613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.934941</td>\n",
       "      <td>0.762916</td>\n",
       "      <td>0.950171</td>\n",
       "      <td>0.785469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.886839</td>\n",
       "      <td>0.851867</td>\n",
       "      <td>0.909636</td>\n",
       "      <td>0.864057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.841103</td>\n",
       "      <td>0.629235</td>\n",
       "      <td>0.868262</td>\n",
       "      <td>0.608607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.893107</td>\n",
       "      <td>0.602278</td>\n",
       "      <td>0.95268</td>\n",
       "      <td>0.712647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.96016</td>\n",
       "      <td>0.880316</td>\n",
       "      <td>0.958726</td>\n",
       "      <td>0.87597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.851947</td>\n",
       "      <td>0.880134</td>\n",
       "      <td>0.91347</td>\n",
       "      <td>0.927532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.843032</td>\n",
       "      <td>0.608251</td>\n",
       "      <td>0.92009</td>\n",
       "      <td>0.692078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.700262</td>\n",
       "      <td>0.633685</td>\n",
       "      <td>0.775085</td>\n",
       "      <td>0.609284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.985643</td>\n",
       "      <td>0.911045</td>\n",
       "      <td>0.989339</td>\n",
       "      <td>0.901438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.835763</td>\n",
       "      <td>0.602579</td>\n",
       "      <td>0.914504</td>\n",
       "      <td>0.664507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.821284</td>\n",
       "      <td>0.760573</td>\n",
       "      <td>0.870051</td>\n",
       "      <td>0.798049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.983104</td>\n",
       "      <td>0.917399</td>\n",
       "      <td>0.975347</td>\n",
       "      <td>0.867527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.836818</td>\n",
       "      <td>0.831244</td>\n",
       "      <td>0.863046</td>\n",
       "      <td>0.819738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.887725</td>\n",
       "      <td>0.474661</td>\n",
       "      <td>0.949483</td>\n",
       "      <td>0.488805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.971782</td>\n",
       "      <td>0.842983</td>\n",
       "      <td>0.982092</td>\n",
       "      <td>0.859604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.764412</td>\n",
       "      <td>0.683318</td>\n",
       "      <td>0.805468</td>\n",
       "      <td>0.613249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.560499</td>\n",
       "      <td>0.347729</td>\n",
       "      <td>0.664335</td>\n",
       "      <td>0.356115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.656932</td>\n",
       "      <td>0.314692</td>\n",
       "      <td>0.614677</td>\n",
       "      <td>0.249032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.829504</td>\n",
       "      <td>0.773994</td>\n",
       "      <td>0.838845</td>\n",
       "      <td>0.746816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.808583</td>\n",
       "      <td>0.716276</td>\n",
       "      <td>0.84014</td>\n",
       "      <td>0.745319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.891395</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.922606</td>\n",
       "      <td>0.8063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.882257</td>\n",
       "      <td>0.724668</td>\n",
       "      <td>0.916183</td>\n",
       "      <td>0.73997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.265399</td>\n",
       "      <td>0.522326</td>\n",
       "      <td>0.296511</td>\n",
       "      <td>0.516559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.877518</td>\n",
       "      <td>0.589231</td>\n",
       "      <td>0.931066</td>\n",
       "      <td>0.571843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  we save your location we are not collect your location  \\\n",
       "Privacy Policy                                                             \n",
       "Google                         0.908582                         0.572177   \n",
       "Aws                            0.910269                          0.86503   \n",
       "AliExpress                     0.746214                          0.27863   \n",
       "Meta                            0.94689                         0.879795   \n",
       "TikTok                         0.831156                         0.667386   \n",
       "YouTube                        0.893129                         0.410609   \n",
       "Waze                           0.867089                         0.654738   \n",
       "Wix                            0.751416                          0.43633   \n",
       "Bookings                        0.90146                          0.86196   \n",
       "whatsapp                       0.820761                         0.822375   \n",
       "apple                          0.935751                         0.837597   \n",
       "wolt                           0.949333                         0.897251   \n",
       "Visa                           0.871648                         0.295689   \n",
       "Mastercard                     0.946313                         0.578801   \n",
       "AirBNB                         0.861365                         0.693184   \n",
       "uber                           0.895697                         0.541264   \n",
       "Spotify                        0.930325                         0.791345   \n",
       "samsung                        0.918832                         0.611802   \n",
       "Wordpress                      0.872656                         0.781054   \n",
       "instagram                      0.912866                         0.578284   \n",
       "MacDonalds                     0.989196                          0.92872   \n",
       "FDA                            0.793556                            0.258   \n",
       "Oracle                         0.903504                         0.715593   \n",
       "Zara                           0.863847                         0.820939   \n",
       "cocacola                       0.909196                         0.837149   \n",
       "Xiaomi                         0.934941                         0.762916   \n",
       "Nasdaq                         0.886839                         0.851867   \n",
       "Walmart                        0.841103                         0.629235   \n",
       "AirCanada                      0.893107                         0.602278   \n",
       "Lufthansa                       0.96016                         0.880316   \n",
       "shopify                        0.851947                         0.880134   \n",
       "Netflix                        0.843032                         0.608251   \n",
       "adobe                          0.700262                         0.633685   \n",
       "Starbucks                      0.985643                         0.911045   \n",
       "Shoppers                       0.835763                         0.602579   \n",
       "Decathlon                      0.821284                         0.760573   \n",
       "waltdisney                     0.983104                         0.917399   \n",
       "AmericanEagle                  0.836818                         0.831244   \n",
       "lululemon                      0.887725                         0.474661   \n",
       "SAP                            0.971782                         0.842983   \n",
       "JetBrains                      0.764412                         0.683318   \n",
       "MySQLCode                      0.560499                         0.347729   \n",
       "Cadens                         0.656932                         0.314692   \n",
       "EpicGames                      0.829504                         0.773994   \n",
       "unitedHealthGroup              0.808583                         0.716276   \n",
       "Slack                          0.891395                         0.784091   \n",
       "SalesForce                     0.882257                         0.724668   \n",
       "JPMorgan                       0.265399                         0.522326   \n",
       "JohnsonAndJohnson              0.877518                         0.589231   \n",
       "\n",
       "                  we save your language we are not collect your language  \n",
       "Privacy Policy                                                            \n",
       "Google                         0.948124                         0.699031  \n",
       "Aws                            0.911911                         0.848358  \n",
       "AliExpress                     0.669556                         0.185862  \n",
       "Meta                           0.957687                         0.839334  \n",
       "TikTok                         0.865321                         0.673416  \n",
       "YouTube                        0.942237                         0.456291  \n",
       "Waze                           0.873169                         0.578474  \n",
       "Wix                            0.816262                         0.628176  \n",
       "Bookings                       0.956732                         0.916293  \n",
       "whatsapp                       0.854267                         0.780319  \n",
       "apple                          0.957964                         0.855723  \n",
       "wolt                           0.974049                         0.940409  \n",
       "Visa                           0.924106                         0.324497  \n",
       "Mastercard                      0.96631                         0.552825  \n",
       "AirBNB                         0.891681                         0.699587  \n",
       "uber                           0.952608                         0.654262  \n",
       "Spotify                        0.953288                         0.780447  \n",
       "samsung                        0.937535                          0.55608  \n",
       "Wordpress                      0.934624                         0.864709  \n",
       "instagram                      0.957693                         0.675045  \n",
       "MacDonalds                     0.990008                         0.965182  \n",
       "FDA                            0.779754                         0.253781  \n",
       "Oracle                         0.915205                         0.695373  \n",
       "Zara                           0.893863                         0.774748  \n",
       "cocacola                       0.915344                          0.78613  \n",
       "Xiaomi                         0.950171                         0.785469  \n",
       "Nasdaq                         0.909636                         0.864057  \n",
       "Walmart                        0.868262                         0.608607  \n",
       "AirCanada                       0.95268                         0.712647  \n",
       "Lufthansa                      0.958726                          0.87597  \n",
       "shopify                         0.91347                         0.927532  \n",
       "Netflix                         0.92009                         0.692078  \n",
       "adobe                          0.775085                         0.609284  \n",
       "Starbucks                      0.989339                         0.901438  \n",
       "Shoppers                       0.914504                         0.664507  \n",
       "Decathlon                      0.870051                         0.798049  \n",
       "waltdisney                     0.975347                         0.867527  \n",
       "AmericanEagle                  0.863046                         0.819738  \n",
       "lululemon                      0.949483                         0.488805  \n",
       "SAP                            0.982092                         0.859604  \n",
       "JetBrains                      0.805468                         0.613249  \n",
       "MySQLCode                      0.664335                         0.356115  \n",
       "Cadens                         0.614677                         0.249032  \n",
       "EpicGames                      0.838845                         0.746816  \n",
       "unitedHealthGroup               0.84014                         0.745319  \n",
       "Slack                          0.922606                           0.8063  \n",
       "SalesForce                     0.916183                          0.73997  \n",
       "JPMorgan                       0.296511                         0.516559  \n",
       "JohnsonAndJohnson              0.931066                         0.571843  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data_security Matrix - data_collection_train_location [6]:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'we save your location'\n",
    "           ,'we are not collect your location'\n",
    "           ,'we save your language'\n",
    "           ,'we are not collect your language']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_ML_location = pd.DataFrame(columns = Phrases)\n",
    "matrix_data_collection_ML_location['Privacy Policy'] = websites\n",
    "matrix_data_collection_ML_location.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_collection_ML_location:\n",
    "        matrix_data_collection_ML_location.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "    \n",
    "matrix_data_collection_ML_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "024b8196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [1 1 1 1 1 0 1 1 1 0 1 0 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.47        15\n",
      "   macro avg       0.29      0.35      0.32        15\n",
      "weighted avg       0.39      0.47      0.42        15\n",
      "\n",
      "Random Forest Classifaier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.67      1.00      0.80        10\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.33      0.50      0.40        15\n",
      "weighted avg       0.44      0.67      0.53        15\n",
      "\n",
      "Logistic Reg Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.67      1.00      0.80        10\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.33      0.50      0.40        15\n",
      "weighted avg       0.44      0.67      0.53        15\n",
      "\n",
      "SVM Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.67      1.00      0.80        10\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.33      0.50      0.40        15\n",
      "weighted avg       0.44      0.67      0.53        15\n",
      "\n",
      "KNN Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.67      1.00      0.80        10\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.33      0.50      0.40        15\n",
      "weighted avg       0.44      0.67      0.53        15\n",
      "\n",
      "neural_network Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.67      1.00      0.80        10\n",
      "\n",
      "    accuracy                           0.67        15\n",
      "   macro avg       0.33      0.50      0.40        15\n",
      "weighted avg       0.44      0.67      0.53        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(matrix_policy_change, policy_change_train\n",
    "#                                                     , test_size=0.5, random_state=42)\n",
    "\n",
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_data_collection_ML_location.iloc[:35,:] \n",
    "X_test = matrix_data_collection_ML_location.iloc[34:,:]\n",
    "y_train = data_collection_train_location[:35]\n",
    "y_test = data_collection_train_location[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "##Logistic Reg Classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "print('Logistic Reg Classifier:', pred_clf)\n",
    "print(classification_report(y_test, pred_clf))\n",
    "\n",
    "##SVM\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM = SVM.fit(X_train, y_train)\n",
    "pred_SVM = SVM.predict(X_test)\n",
    "print('SVM Classifier:', pred_SVM)\n",
    "print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN Classifier:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network Classifier:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3d06989",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_location = pred_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3f9486a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>we save your IP address</th>\n",
       "      <th>we are not collect your browser and device details</th>\n",
       "      <th>we save your browser and device details</th>\n",
       "      <th>we are not collect your IP address</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.927285</td>\n",
       "      <td>0.399406</td>\n",
       "      <td>0.958664</td>\n",
       "      <td>0.730843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.864911</td>\n",
       "      <td>0.811091</td>\n",
       "      <td>0.941885</td>\n",
       "      <td>0.669195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.794322</td>\n",
       "      <td>0.274946</td>\n",
       "      <td>0.834416</td>\n",
       "      <td>0.273507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.95552</td>\n",
       "      <td>0.915104</td>\n",
       "      <td>0.971475</td>\n",
       "      <td>0.951077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.824655</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.824444</td>\n",
       "      <td>0.719136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.923553</td>\n",
       "      <td>0.215291</td>\n",
       "      <td>0.942502</td>\n",
       "      <td>0.566714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.826572</td>\n",
       "      <td>0.325615</td>\n",
       "      <td>0.909045</td>\n",
       "      <td>0.369936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.829918</td>\n",
       "      <td>0.408896</td>\n",
       "      <td>0.879059</td>\n",
       "      <td>0.527915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.959671</td>\n",
       "      <td>0.684412</td>\n",
       "      <td>0.988619</td>\n",
       "      <td>0.860105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.780747</td>\n",
       "      <td>0.518307</td>\n",
       "      <td>0.732282</td>\n",
       "      <td>0.574262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.929299</td>\n",
       "      <td>0.78877</td>\n",
       "      <td>0.96545</td>\n",
       "      <td>0.827847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.970565</td>\n",
       "      <td>0.884429</td>\n",
       "      <td>0.969672</td>\n",
       "      <td>0.895662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.926318</td>\n",
       "      <td>0.274361</td>\n",
       "      <td>0.910132</td>\n",
       "      <td>0.320057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.95593</td>\n",
       "      <td>0.366818</td>\n",
       "      <td>0.969587</td>\n",
       "      <td>0.702033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.862906</td>\n",
       "      <td>0.668417</td>\n",
       "      <td>0.928456</td>\n",
       "      <td>0.651174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.955241</td>\n",
       "      <td>0.47228</td>\n",
       "      <td>0.939661</td>\n",
       "      <td>0.350367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.950144</td>\n",
       "      <td>0.431162</td>\n",
       "      <td>0.972678</td>\n",
       "      <td>0.723763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.957606</td>\n",
       "      <td>0.205367</td>\n",
       "      <td>0.945739</td>\n",
       "      <td>0.453599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.91469</td>\n",
       "      <td>0.841974</td>\n",
       "      <td>0.896997</td>\n",
       "      <td>0.86868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.941601</td>\n",
       "      <td>0.568644</td>\n",
       "      <td>0.936974</td>\n",
       "      <td>0.762283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.994073</td>\n",
       "      <td>0.861556</td>\n",
       "      <td>0.99465</td>\n",
       "      <td>0.946224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.782413</td>\n",
       "      <td>0.222564</td>\n",
       "      <td>0.840003</td>\n",
       "      <td>0.215339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.922285</td>\n",
       "      <td>0.51469</td>\n",
       "      <td>0.940582</td>\n",
       "      <td>0.808936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.908113</td>\n",
       "      <td>0.834406</td>\n",
       "      <td>0.967439</td>\n",
       "      <td>0.862525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.893423</td>\n",
       "      <td>0.84579</td>\n",
       "      <td>0.943595</td>\n",
       "      <td>0.848783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.946725</td>\n",
       "      <td>0.702301</td>\n",
       "      <td>0.955698</td>\n",
       "      <td>0.769944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.921772</td>\n",
       "      <td>0.8323</td>\n",
       "      <td>0.944036</td>\n",
       "      <td>0.875005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.871276</td>\n",
       "      <td>0.411801</td>\n",
       "      <td>0.800625</td>\n",
       "      <td>0.716986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.945853</td>\n",
       "      <td>0.364547</td>\n",
       "      <td>0.935371</td>\n",
       "      <td>0.768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.955986</td>\n",
       "      <td>0.822826</td>\n",
       "      <td>0.960859</td>\n",
       "      <td>0.900149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.878421</td>\n",
       "      <td>0.867004</td>\n",
       "      <td>0.869042</td>\n",
       "      <td>0.910646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.853241</td>\n",
       "      <td>0.399141</td>\n",
       "      <td>0.900869</td>\n",
       "      <td>0.600128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.810378</td>\n",
       "      <td>0.479882</td>\n",
       "      <td>0.804395</td>\n",
       "      <td>0.679751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.986278</td>\n",
       "      <td>0.894738</td>\n",
       "      <td>0.993387</td>\n",
       "      <td>0.772972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.878311</td>\n",
       "      <td>0.559476</td>\n",
       "      <td>0.918985</td>\n",
       "      <td>0.660296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.856672</td>\n",
       "      <td>0.699373</td>\n",
       "      <td>0.818551</td>\n",
       "      <td>0.747491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.985278</td>\n",
       "      <td>0.853731</td>\n",
       "      <td>0.992789</td>\n",
       "      <td>0.935188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.906228</td>\n",
       "      <td>0.575401</td>\n",
       "      <td>0.922231</td>\n",
       "      <td>0.815638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.923586</td>\n",
       "      <td>0.446688</td>\n",
       "      <td>0.935437</td>\n",
       "      <td>0.360705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.976334</td>\n",
       "      <td>0.649337</td>\n",
       "      <td>0.966649</td>\n",
       "      <td>0.856395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.818962</td>\n",
       "      <td>0.375137</td>\n",
       "      <td>0.896784</td>\n",
       "      <td>0.643723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.555059</td>\n",
       "      <td>0.166016</td>\n",
       "      <td>0.660379</td>\n",
       "      <td>0.375012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.561794</td>\n",
       "      <td>0.161306</td>\n",
       "      <td>0.962041</td>\n",
       "      <td>0.553758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.817144</td>\n",
       "      <td>0.651837</td>\n",
       "      <td>0.924166</td>\n",
       "      <td>0.75789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.800024</td>\n",
       "      <td>0.691779</td>\n",
       "      <td>0.877163</td>\n",
       "      <td>0.754895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.924415</td>\n",
       "      <td>0.595109</td>\n",
       "      <td>0.938631</td>\n",
       "      <td>0.771259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.889319</td>\n",
       "      <td>0.694457</td>\n",
       "      <td>0.916668</td>\n",
       "      <td>0.752113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.334656</td>\n",
       "      <td>0.245528</td>\n",
       "      <td>0.981967</td>\n",
       "      <td>0.762289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.919702</td>\n",
       "      <td>0.45815</td>\n",
       "      <td>0.9562</td>\n",
       "      <td>0.489848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  we save your IP address  \\\n",
       "Privacy Policy                              \n",
       "Google                           0.927285   \n",
       "Aws                              0.864911   \n",
       "AliExpress                       0.794322   \n",
       "Meta                              0.95552   \n",
       "TikTok                           0.824655   \n",
       "YouTube                          0.923553   \n",
       "Waze                             0.826572   \n",
       "Wix                              0.829918   \n",
       "Bookings                         0.959671   \n",
       "whatsapp                         0.780747   \n",
       "apple                            0.929299   \n",
       "wolt                             0.970565   \n",
       "Visa                             0.926318   \n",
       "Mastercard                        0.95593   \n",
       "AirBNB                           0.862906   \n",
       "uber                             0.955241   \n",
       "Spotify                          0.950144   \n",
       "samsung                          0.957606   \n",
       "Wordpress                         0.91469   \n",
       "instagram                        0.941601   \n",
       "MacDonalds                       0.994073   \n",
       "FDA                              0.782413   \n",
       "Oracle                           0.922285   \n",
       "Zara                             0.908113   \n",
       "cocacola                         0.893423   \n",
       "Xiaomi                           0.946725   \n",
       "Nasdaq                           0.921772   \n",
       "Walmart                          0.871276   \n",
       "AirCanada                        0.945853   \n",
       "Lufthansa                        0.955986   \n",
       "shopify                          0.878421   \n",
       "Netflix                          0.853241   \n",
       "adobe                            0.810378   \n",
       "Starbucks                        0.986278   \n",
       "Shoppers                         0.878311   \n",
       "Decathlon                        0.856672   \n",
       "waltdisney                       0.985278   \n",
       "AmericanEagle                    0.906228   \n",
       "lululemon                        0.923586   \n",
       "SAP                              0.976334   \n",
       "JetBrains                        0.818962   \n",
       "MySQLCode                        0.555059   \n",
       "Cadens                           0.561794   \n",
       "EpicGames                        0.817144   \n",
       "unitedHealthGroup                0.800024   \n",
       "Slack                            0.924415   \n",
       "SalesForce                       0.889319   \n",
       "JPMorgan                         0.334656   \n",
       "JohnsonAndJohnson                0.919702   \n",
       "\n",
       "                  we are not collect your browser and device details  \\\n",
       "Privacy Policy                                                         \n",
       "Google                                                      0.399406   \n",
       "Aws                                                         0.811091   \n",
       "AliExpress                                                  0.274946   \n",
       "Meta                                                        0.915104   \n",
       "TikTok                                                      0.523605   \n",
       "YouTube                                                     0.215291   \n",
       "Waze                                                        0.325615   \n",
       "Wix                                                         0.408896   \n",
       "Bookings                                                    0.684412   \n",
       "whatsapp                                                    0.518307   \n",
       "apple                                                        0.78877   \n",
       "wolt                                                        0.884429   \n",
       "Visa                                                        0.274361   \n",
       "Mastercard                                                  0.366818   \n",
       "AirBNB                                                      0.668417   \n",
       "uber                                                         0.47228   \n",
       "Spotify                                                     0.431162   \n",
       "samsung                                                     0.205367   \n",
       "Wordpress                                                   0.841974   \n",
       "instagram                                                   0.568644   \n",
       "MacDonalds                                                  0.861556   \n",
       "FDA                                                         0.222564   \n",
       "Oracle                                                       0.51469   \n",
       "Zara                                                        0.834406   \n",
       "cocacola                                                     0.84579   \n",
       "Xiaomi                                                      0.702301   \n",
       "Nasdaq                                                        0.8323   \n",
       "Walmart                                                     0.411801   \n",
       "AirCanada                                                   0.364547   \n",
       "Lufthansa                                                   0.822826   \n",
       "shopify                                                     0.867004   \n",
       "Netflix                                                     0.399141   \n",
       "adobe                                                       0.479882   \n",
       "Starbucks                                                   0.894738   \n",
       "Shoppers                                                    0.559476   \n",
       "Decathlon                                                   0.699373   \n",
       "waltdisney                                                  0.853731   \n",
       "AmericanEagle                                               0.575401   \n",
       "lululemon                                                   0.446688   \n",
       "SAP                                                         0.649337   \n",
       "JetBrains                                                   0.375137   \n",
       "MySQLCode                                                   0.166016   \n",
       "Cadens                                                      0.161306   \n",
       "EpicGames                                                   0.651837   \n",
       "unitedHealthGroup                                           0.691779   \n",
       "Slack                                                       0.595109   \n",
       "SalesForce                                                  0.694457   \n",
       "JPMorgan                                                    0.245528   \n",
       "JohnsonAndJohnson                                            0.45815   \n",
       "\n",
       "                  we save your browser and device details  \\\n",
       "Privacy Policy                                              \n",
       "Google                                           0.958664   \n",
       "Aws                                              0.941885   \n",
       "AliExpress                                       0.834416   \n",
       "Meta                                             0.971475   \n",
       "TikTok                                           0.824444   \n",
       "YouTube                                          0.942502   \n",
       "Waze                                             0.909045   \n",
       "Wix                                              0.879059   \n",
       "Bookings                                         0.988619   \n",
       "whatsapp                                         0.732282   \n",
       "apple                                             0.96545   \n",
       "wolt                                             0.969672   \n",
       "Visa                                             0.910132   \n",
       "Mastercard                                       0.969587   \n",
       "AirBNB                                           0.928456   \n",
       "uber                                             0.939661   \n",
       "Spotify                                          0.972678   \n",
       "samsung                                          0.945739   \n",
       "Wordpress                                        0.896997   \n",
       "instagram                                        0.936974   \n",
       "MacDonalds                                        0.99465   \n",
       "FDA                                              0.840003   \n",
       "Oracle                                           0.940582   \n",
       "Zara                                             0.967439   \n",
       "cocacola                                         0.943595   \n",
       "Xiaomi                                           0.955698   \n",
       "Nasdaq                                           0.944036   \n",
       "Walmart                                          0.800625   \n",
       "AirCanada                                        0.935371   \n",
       "Lufthansa                                        0.960859   \n",
       "shopify                                          0.869042   \n",
       "Netflix                                          0.900869   \n",
       "adobe                                            0.804395   \n",
       "Starbucks                                        0.993387   \n",
       "Shoppers                                         0.918985   \n",
       "Decathlon                                        0.818551   \n",
       "waltdisney                                       0.992789   \n",
       "AmericanEagle                                    0.922231   \n",
       "lululemon                                        0.935437   \n",
       "SAP                                              0.966649   \n",
       "JetBrains                                        0.896784   \n",
       "MySQLCode                                        0.660379   \n",
       "Cadens                                           0.962041   \n",
       "EpicGames                                        0.924166   \n",
       "unitedHealthGroup                                0.877163   \n",
       "Slack                                            0.938631   \n",
       "SalesForce                                       0.916668   \n",
       "JPMorgan                                         0.981967   \n",
       "JohnsonAndJohnson                                  0.9562   \n",
       "\n",
       "                  we are not collect your IP address  \n",
       "Privacy Policy                                        \n",
       "Google                                      0.730843  \n",
       "Aws                                         0.669195  \n",
       "AliExpress                                  0.273507  \n",
       "Meta                                        0.951077  \n",
       "TikTok                                      0.719136  \n",
       "YouTube                                     0.566714  \n",
       "Waze                                        0.369936  \n",
       "Wix                                         0.527915  \n",
       "Bookings                                    0.860105  \n",
       "whatsapp                                    0.574262  \n",
       "apple                                       0.827847  \n",
       "wolt                                        0.895662  \n",
       "Visa                                        0.320057  \n",
       "Mastercard                                  0.702033  \n",
       "AirBNB                                      0.651174  \n",
       "uber                                        0.350367  \n",
       "Spotify                                     0.723763  \n",
       "samsung                                     0.453599  \n",
       "Wordpress                                    0.86868  \n",
       "instagram                                   0.762283  \n",
       "MacDonalds                                  0.946224  \n",
       "FDA                                         0.215339  \n",
       "Oracle                                      0.808936  \n",
       "Zara                                        0.862525  \n",
       "cocacola                                    0.848783  \n",
       "Xiaomi                                      0.769944  \n",
       "Nasdaq                                      0.875005  \n",
       "Walmart                                     0.716986  \n",
       "AirCanada                                      0.768  \n",
       "Lufthansa                                   0.900149  \n",
       "shopify                                     0.910646  \n",
       "Netflix                                     0.600128  \n",
       "adobe                                       0.679751  \n",
       "Starbucks                                   0.772972  \n",
       "Shoppers                                    0.660296  \n",
       "Decathlon                                   0.747491  \n",
       "waltdisney                                  0.935188  \n",
       "AmericanEagle                               0.815638  \n",
       "lululemon                                   0.360705  \n",
       "SAP                                         0.856395  \n",
       "JetBrains                                   0.643723  \n",
       "MySQLCode                                   0.375012  \n",
       "Cadens                                      0.553758  \n",
       "EpicGames                                    0.75789  \n",
       "unitedHealthGroup                           0.754895  \n",
       "Slack                                       0.771259  \n",
       "SalesForce                                  0.752113  \n",
       "JPMorgan                                    0.762289  \n",
       "JohnsonAndJohnson                           0.489848  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data_security Matrix - data_collection_train_IP [7]:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'we save your IP address'\n",
    "           ,'we are not collect your browser and device details'\n",
    "           ,'we save your browser and device details'\n",
    "           ,'we are not collect your IP address']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_ML_IP = pd.DataFrame(columns = Phrases)\n",
    "matrix_data_collection_ML_IP['Privacy Policy'] = websites\n",
    "matrix_data_collection_ML_IP.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_collection_ML_IP:\n",
    "        matrix_data_collection_ML_IP.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "    \n",
    "matrix_data_collection_ML_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08c92afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [1 1 1 1 0 1 1 1 1 1 1 0 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.87      0.93        15\n",
      "\n",
      "    accuracy                           0.87        15\n",
      "   macro avg       0.50      0.43      0.46        15\n",
      "weighted avg       1.00      0.87      0.93        15\n",
      "\n",
      "Random Forest Classifaier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "Logistic Reg Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "SVM Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "KNN Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "neural_network Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(matrix_policy_change, policy_change_train\n",
    "#                                                     , test_size=0.5, random_state=42)\n",
    "\n",
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_data_collection_ML_IP.iloc[:35,:] \n",
    "X_test = matrix_data_collection_ML_IP.iloc[34:,:]\n",
    "y_train = data_collection_train_IP[:35]\n",
    "y_test = data_collection_train_IP[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "##Logistic Reg Classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "print('Logistic Reg Classifier:', pred_clf)\n",
    "print(classification_report(y_test, pred_clf))\n",
    "\n",
    "##SVM\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM = SVM.fit(X_train, y_train)\n",
    "pred_SVM = SVM.predict(X_test)\n",
    "print('SVM Classifier:', pred_SVM)\n",
    "print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN Classifier:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network Classifier:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d083b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_IP = pred_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8b8e78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>we save your passwords</th>\n",
       "      <th>we are not collect your passwords</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.803548</td>\n",
       "      <td>0.392315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.607057</td>\n",
       "      <td>0.392887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.158173</td>\n",
       "      <td>0.073476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.825558</td>\n",
       "      <td>0.588022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.749715</td>\n",
       "      <td>0.585331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.759953</td>\n",
       "      <td>0.23613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.46796</td>\n",
       "      <td>0.274605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.362792</td>\n",
       "      <td>0.231374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.655465</td>\n",
       "      <td>0.648127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.329352</td>\n",
       "      <td>0.310132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.657116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.709536</td>\n",
       "      <td>0.550528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.818451</td>\n",
       "      <td>0.250275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.706839</td>\n",
       "      <td>0.234305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.677104</td>\n",
       "      <td>0.467039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.632849</td>\n",
       "      <td>0.255799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.529871</td>\n",
       "      <td>0.371031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.64305</td>\n",
       "      <td>0.2765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.509428</td>\n",
       "      <td>0.38026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.692587</td>\n",
       "      <td>0.305557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.991621</td>\n",
       "      <td>0.963572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.441948</td>\n",
       "      <td>0.085091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.498484</td>\n",
       "      <td>0.355963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.601751</td>\n",
       "      <td>0.517187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.82966</td>\n",
       "      <td>0.647654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.891902</td>\n",
       "      <td>0.666709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.861225</td>\n",
       "      <td>0.800862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.356107</td>\n",
       "      <td>0.289397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.619577</td>\n",
       "      <td>0.36343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.857198</td>\n",
       "      <td>0.711897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.356075</td>\n",
       "      <td>0.38414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.654177</td>\n",
       "      <td>0.455816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.424913</td>\n",
       "      <td>0.414055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.889385</td>\n",
       "      <td>0.603787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.410215</td>\n",
       "      <td>0.29209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.423882</td>\n",
       "      <td>0.350689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.930565</td>\n",
       "      <td>0.662519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.626837</td>\n",
       "      <td>0.626676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.736076</td>\n",
       "      <td>0.297808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.86211</td>\n",
       "      <td>0.627204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.49138</td>\n",
       "      <td>0.352931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.229935</td>\n",
       "      <td>0.215151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.3378</td>\n",
       "      <td>0.1761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.832233</td>\n",
       "      <td>0.662521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.643249</td>\n",
       "      <td>0.532596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.711996</td>\n",
       "      <td>0.516373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.553058</td>\n",
       "      <td>0.382881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.088095</td>\n",
       "      <td>0.28471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.614449</td>\n",
       "      <td>0.267625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  we save your passwords we are not collect your passwords\n",
       "Privacy Policy                                                            \n",
       "Google                          0.803548                          0.392315\n",
       "Aws                             0.607057                          0.392887\n",
       "AliExpress                      0.158173                          0.073476\n",
       "Meta                            0.825558                          0.588022\n",
       "TikTok                          0.749715                          0.585331\n",
       "YouTube                         0.759953                           0.23613\n",
       "Waze                             0.46796                          0.274605\n",
       "Wix                             0.362792                          0.231374\n",
       "Bookings                        0.655465                          0.648127\n",
       "whatsapp                        0.329352                          0.310132\n",
       "apple                              0.836                          0.657116\n",
       "wolt                            0.709536                          0.550528\n",
       "Visa                            0.818451                          0.250275\n",
       "Mastercard                      0.706839                          0.234305\n",
       "AirBNB                          0.677104                          0.467039\n",
       "uber                            0.632849                          0.255799\n",
       "Spotify                         0.529871                          0.371031\n",
       "samsung                          0.64305                            0.2765\n",
       "Wordpress                       0.509428                           0.38026\n",
       "instagram                       0.692587                          0.305557\n",
       "MacDonalds                      0.991621                          0.963572\n",
       "FDA                             0.441948                          0.085091\n",
       "Oracle                          0.498484                          0.355963\n",
       "Zara                            0.601751                          0.517187\n",
       "cocacola                         0.82966                          0.647654\n",
       "Xiaomi                          0.891902                          0.666709\n",
       "Nasdaq                          0.861225                          0.800862\n",
       "Walmart                         0.356107                          0.289397\n",
       "AirCanada                       0.619577                           0.36343\n",
       "Lufthansa                       0.857198                          0.711897\n",
       "shopify                         0.356075                           0.38414\n",
       "Netflix                         0.654177                          0.455816\n",
       "adobe                           0.424913                          0.414055\n",
       "Starbucks                       0.889385                          0.603787\n",
       "Shoppers                        0.410215                           0.29209\n",
       "Decathlon                       0.423882                          0.350689\n",
       "waltdisney                      0.930565                          0.662519\n",
       "AmericanEagle                   0.626837                          0.626676\n",
       "lululemon                       0.736076                          0.297808\n",
       "SAP                              0.86211                          0.627204\n",
       "JetBrains                        0.49138                          0.352931\n",
       "MySQLCode                       0.229935                          0.215151\n",
       "Cadens                            0.3378                            0.1761\n",
       "EpicGames                       0.832233                          0.662521\n",
       "unitedHealthGroup               0.643249                          0.532596\n",
       "Slack                           0.711996                          0.516373\n",
       "SalesForce                      0.553058                          0.382881\n",
       "JPMorgan                        0.088095                           0.28471\n",
       "JohnsonAndJohnson               0.614449                          0.267625"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##data_security Matrix - data_collection_train_passward [8]:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'we save your passwords'\n",
    "           ,'we are not collect your passwords']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_ML_passward = pd.DataFrame(columns = Phrases)\n",
    "matrix_data_collection_ML_passward['Privacy Policy'] = websites\n",
    "matrix_data_collection_ML_passward.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_collection_ML_passward:\n",
    "        matrix_data_collection_ML_passward.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "    \n",
    "matrix_data_collection_ML_passward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49e4882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.62      0.50         8\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.33        15\n",
      "   macro avg       0.21      0.31      0.25        15\n",
      "weighted avg       0.22      0.33      0.27        15\n",
      "\n",
      "Random Forest Classifaier: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.70         8\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "Logistic Reg Classifier: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.70         8\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "SVM Classifier: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.70         8\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "KNN Classifier: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.70         8\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n",
      "neural_network Classifier: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.70         8\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.53        15\n",
      "   macro avg       0.27      0.50      0.35        15\n",
      "weighted avg       0.28      0.53      0.37        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(matrix_policy_change, policy_change_train\n",
    "#                                                     , test_size=0.5, random_state=42)\n",
    "\n",
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_data_collection_ML_passward.iloc[:35,:] \n",
    "X_test = matrix_data_collection_ML_passward.iloc[34:,:]\n",
    "y_train = data_collection_train_passward[:35]\n",
    "y_test = data_collection_train_passward[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "##Logistic Reg Classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "print('Logistic Reg Classifier:', pred_clf)\n",
    "print(classification_report(y_test, pred_clf))\n",
    "\n",
    "##SVM\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM = SVM.fit(X_train, y_train)\n",
    "pred_SVM = SVM.predict(X_test)\n",
    "print('SVM Classifier:', pred_SVM)\n",
    "print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN Classifier:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network Classifier:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47b07483",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_passward = pred_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74434730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.8875\n",
      "Precision: 0.7888888888888889\n",
      "Accuracy: 0.7666666666666667\n",
      "F1 Score: 0.8352941176470589\n"
     ]
    }
   ],
   "source": [
    "#Data Collection Parameter:\n",
    "index = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "for i in data_collection_train_personal[34:]:\n",
    "    if pred_personal[index]==1 and data_collection_train_personal[index+34]==1:\n",
    "        TP +=1\n",
    "    elif pred_personal[index]==0 and data_collection_train_personal[index+34]==0:\n",
    "        TN +=1\n",
    "    elif pred_personal[index]==0 and data_collection_train_personal[index+34]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_collection_train_media[34:]:\n",
    "    if pred_media[index]==1 and data_collection_train_media[index+34]==1:\n",
    "        TP +=1\n",
    "    elif pred_media[index]==0 and data_collection_train_media[index+34]==0:\n",
    "        TN +=1\n",
    "    elif pred_media[index]==0 and data_collection_train_media[index+34]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_collection_train_browser[34:]:\n",
    "    if pred_browser[index]==1 and data_collection_train_browser[index+34]==1:\n",
    "        TP +=1\n",
    "    elif pred_browser[index]==0 and data_collection_train_browser[index+34]==0:\n",
    "        TN +=1\n",
    "    elif pred_browser[index]==0 and data_collection_train_browser[index+34]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_collection_train_voice[34:]:\n",
    "    if pred_voice[index]==1 and data_collection_train_voice[index+34]==1:\n",
    "        TP +=1\n",
    "    elif pred_voice[index]==0 and data_collection_train_voice[index+34]==0:\n",
    "        TN +=1\n",
    "    elif pred_voice[index]==0 and data_collection_train_voice[index+34]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0   \n",
    "for i in data_collection_train_payments[34:]:\n",
    "    if pred_payments[index]==1 and data_collection_train_payments[index+34]==1:\n",
    "        TP +=1\n",
    "    elif pred_payments[index]==0 and data_collection_train_payments[index+34]==0:\n",
    "        TN +=1\n",
    "    elif pred_payments[index]==0 and data_collection_train_payments[index+34]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_collection_train_location[34:]:\n",
    "    if pred_location[index]==1 and data_collection_train_location[index+34]==1:\n",
    "        TP +=1\n",
    "    elif pred_location[index]==0 and data_collection_train_location[index+34]==0:\n",
    "        TN +=1\n",
    "    elif pred_location[index]==0 and data_collection_train_location[index+34]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_collection_train_IP[34:]:\n",
    "    if pred_IP[index]==1 and data_collection_train_IP[index+34]==1:\n",
    "        TP +=1\n",
    "    elif pred_IP[index]==0 and data_collection_train_IP[index+34]==0:\n",
    "        TN +=1\n",
    "    elif pred_IP[index]==0 and data_collection_train_IP[index+34]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_collection_train_passward[34:]:\n",
    "    if pred_passward[index]==1 and data_collection_train_passward[index+34]==1:\n",
    "        TP +=1\n",
    "    elif pred_passward[index]==0 and data_collection_train_passward[index+34]==0:\n",
    "        TN +=1\n",
    "    elif pred_passward[index]==0 and data_collection_train_passward[index+34]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "recall = TP/(TP+FN)\n",
    "Precision = TP/(TP+FP)\n",
    "Accuracy = (TP+TN)/(TP+FP+FN+TN) \n",
    "F1 = (TP)/(TP+(0.5*(FP+FN)))\n",
    "\n",
    "print(\"recall:\" , recall)\n",
    "print(\"Precision:\" , Precision)\n",
    "print(\"Accuracy:\" , Accuracy)\n",
    "print(\"F1 Score:\" , F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eabe28d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_Median_personal = matrix_data_collection_ML_personal.transpose()\n",
    "    \n",
    "#add the avg and median rows:\n",
    "matrix_data_collection_Median_personal.loc['Median'] =  matrix_data_collection_Median_personal.median()\n",
    "matrix_data_collection_Median_personal.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "data_collection_train_pred_Median_personal = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_data_collection_Median_personal:\n",
    "    num = matrix_data_collection_Median_personal[websites[websites_index]].loc['Median']\n",
    "    if num >0.2:\n",
    "        data_collection_train_pred_Median_personal.append(1)\n",
    "    else:\n",
    "        data_collection_train_pred_Median_personal.append(0)\n",
    "    websites_index += 1\n",
    " \n",
    "print(data_collection_train_pred_Median_personal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2139af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_Median_media = matrix_data_collection_ML_media.transpose()\n",
    "    \n",
    "#add the avg and median rows:\n",
    "matrix_data_collection_Median_media.loc['Median'] =  matrix_data_collection_Median_media.median()\n",
    "matrix_data_collection_Median_media.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "data_collection_train_pred_Median_media = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_data_collection_Median_media:\n",
    "    num = matrix_data_collection_Median_media[websites[websites_index]].loc['Median']\n",
    "    if num >0.5:\n",
    "        data_collection_train_pred_Median_media.append(1)\n",
    "    else:\n",
    "        data_collection_train_pred_Median_media.append(0)\n",
    "    websites_index += 1\n",
    " \n",
    "print(data_collection_train_pred_Median_media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f66060e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_Median_browser = matrix_data_collection_ML_browser.transpose()\n",
    "    \n",
    "#add the avg and median rows:\n",
    "matrix_data_collection_Median_browser.loc['Median'] =  matrix_data_collection_Median_browser.median()\n",
    "matrix_data_collection_Median_browser.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "data_collection_train_pred_Median_browser = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_data_collection_Median_browser:\n",
    "    num = matrix_data_collection_Median_browser[websites[websites_index]].loc['Median']\n",
    "    if num >0.5:\n",
    "        data_collection_train_pred_Median_browser.append(1)\n",
    "    else:\n",
    "        data_collection_train_pred_Median_browser.append(0)\n",
    "    websites_index += 1\n",
    " \n",
    "print(data_collection_train_pred_Median_browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e603d740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_Median_voice = matrix_data_collection_ML_voice.transpose()\n",
    "    \n",
    "#add the avg and median rows:\n",
    "matrix_data_collection_Median_voice.loc['Median'] =  matrix_data_collection_Median_voice.median()\n",
    "matrix_data_collection_Median_voice.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "data_collection_train_pred_Median_voice = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_data_collection_Median_voice:\n",
    "    num = matrix_data_collection_Median_voice[websites[websites_index]].loc['Median']\n",
    "    if num >0.7:\n",
    "        data_collection_train_pred_Median_voice.append(1)\n",
    "    else:\n",
    "        data_collection_train_pred_Median_voice.append(0)\n",
    "    websites_index += 1\n",
    " \n",
    "print(data_collection_train_pred_Median_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e76100b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_Median_payments = matrix_data_collecting_ML_payments.transpose()\n",
    "    \n",
    "#add the avg and median rows:\n",
    "matrix_data_collection_Median_payments.loc['Median'] =  matrix_data_collection_Median_payments.median()\n",
    "matrix_data_collection_Median_payments.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "data_collection_train_pred_Median_payments = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_data_collection_Median_payments:\n",
    "    num = matrix_data_collection_Median_payments[websites[websites_index]].loc['Median']\n",
    "    if num >0.6:\n",
    "        data_collection_train_pred_Median_payments.append(1)\n",
    "    else:\n",
    "        data_collection_train_pred_Median_payments.append(0)\n",
    "    websites_index += 1\n",
    " \n",
    "print(data_collection_train_pred_Median_payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f1afb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_Median_location = matrix_data_collection_ML_location.transpose()\n",
    "    \n",
    "#add the avg and median rows:\n",
    "matrix_data_collection_Median_location.loc['Median'] =  matrix_data_collection_Median_location.median()\n",
    "matrix_data_collection_Median_location.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "data_collection_train_pred_Median_location = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_data_collection_Median_location:\n",
    "    num = matrix_data_collection_Median_location[websites[websites_index]].loc['Median']\n",
    "    if num >0.5:\n",
    "        data_collection_train_pred_Median_location.append(1)\n",
    "    else:\n",
    "        data_collection_train_pred_Median_location.append(0)\n",
    "    websites_index += 1\n",
    " \n",
    "print(data_collection_train_pred_Median_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0fdee460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_Median_IP = matrix_data_collection_ML_IP.transpose()\n",
    "    \n",
    "#add the avg and median rows:\n",
    "matrix_data_collection_Median_IP.loc['Median'] =  matrix_data_collection_Median_IP.median()\n",
    "matrix_data_collection_Median_IP.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "data_collection_train_pred_Median_IP = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_data_collection_Median_IP:\n",
    "    num = matrix_data_collection_Median_IP[websites[websites_index]].loc['Median']\n",
    "    if num >0.6:\n",
    "        data_collection_train_pred_Median_IP.append(1)\n",
    "    else:\n",
    "        data_collection_train_pred_Median_IP.append(0)\n",
    "    websites_index += 1\n",
    " \n",
    "print(data_collection_train_pred_Median_IP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50b142f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_data_collection_Median_passward = matrix_data_collection_ML_passward.transpose()\n",
    "    \n",
    "#add the avg and median rows:\n",
    "matrix_data_collection_Median_passward.loc['Median'] =  matrix_data_collection_Median_passward.median()\n",
    "matrix_data_collection_Median_passward.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "data_collection_train_pred_Median_passward = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_data_collection_Median_passward:\n",
    "    num = matrix_data_collection_Median_passward[websites[websites_index]].loc['Median']\n",
    "    if num >0.7:\n",
    "        data_collection_train_pred_Median_passward.append(1)\n",
    "    else:\n",
    "        data_collection_train_pred_Median_passward.append(0)\n",
    "    websites_index += 1\n",
    " \n",
    "print(data_collection_train_pred_Median_passward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "058d986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.895910780669145\n",
      "Precision: 0.7438271604938271\n",
      "Accuracy: 0.7168367346938775\n",
      "F1 Score: 0.8128161888701517\n"
     ]
    }
   ],
   "source": [
    "#Data Collection Parameter:\n",
    "index = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "for i in data_collection_train_pred_Median_personal:\n",
    "    if data_collection_train_pred_Median_personal[index]==1 and data_collection_train_personal[index]==1:\n",
    "        TP +=1\n",
    "    elif data_collection_train_pred_Median_personal[index]==0 and data_collection_train_personal[index]==0:\n",
    "        TN +=1\n",
    "    elif data_collection_train_pred_Median_personal[index]==0 and data_collection_train_personal[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_collection_train_pred_Median_media:\n",
    "    if data_collection_train_pred_Median_media[index]==1 and data_collection_train_media[index]==1:\n",
    "        TP +=1\n",
    "    elif data_collection_train_pred_Median_media[index]==0 and data_collection_train_media[index]==0:\n",
    "        TN +=1\n",
    "    elif data_collection_train_pred_Median_media[index]==0 and data_collection_train_media[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_collection_train_pred_Median_browser:\n",
    "    if data_collection_train_pred_Median_browser[index]==1 and data_collection_train_browser[index]==1:\n",
    "        TP +=1\n",
    "    elif data_collection_train_pred_Median_browser[index]==0 and data_collection_train_browser[index]==0:\n",
    "        TN +=1\n",
    "    elif data_collection_train_pred_Median_browser[index]==0 and data_collection_train_browser[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_collection_train_pred_Median_voice:\n",
    "    if data_collection_train_pred_Median_voice[index]==1 and data_collection_train_voice[index]==1:\n",
    "        TP +=1\n",
    "    elif data_collection_train_pred_Median_voice[index]==0 and data_collection_train_voice[index]==0:\n",
    "        TN +=1\n",
    "    elif data_collection_train_pred_Median_voice[index]==0 and data_collection_train_voice[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0   \n",
    "for i in data_collection_train_pred_Median_payments:\n",
    "    if data_collection_train_pred_Median_payments[index]==1 and data_collection_train_payments[index]==1:\n",
    "        TP +=1\n",
    "    elif data_collection_train_pred_Median_payments[index]==0 and data_collection_train_payments[index]==0:\n",
    "        TN +=1\n",
    "    elif data_collection_train_pred_Median_payments[index]==0 and data_collection_train_payments[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_collection_train_pred_Median_location:\n",
    "    if data_collection_train_pred_Median_location[index]==1 and data_collection_train_location[index]==1:\n",
    "        TP +=1\n",
    "    elif data_collection_train_pred_Median_location[index]==0 and data_collection_train_location[index]==0:\n",
    "        TN +=1\n",
    "    elif data_collection_train_pred_Median_location[index]==0 and data_collection_train_location[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_collection_train_pred_Median_IP:\n",
    "    if data_collection_train_pred_Median_IP[index]==1 and data_collection_train_IP[index]==1:\n",
    "        TP +=1\n",
    "    elif data_collection_train_pred_Median_IP[index]==0 and data_collection_train_IP[index]==0:\n",
    "        TN +=1\n",
    "    elif data_collection_train_pred_Median_IP[index]==0 and data_collection_train_IP[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_collection_train_pred_Median_passward:\n",
    "    if data_collection_train_pred_Median_passward[index]==1 and data_collection_train_passward[index]==1:\n",
    "        TP +=1\n",
    "    elif data_collection_train_pred_Median_passward[index]==0 and data_collection_train_passward[index]==0:\n",
    "        TN +=1\n",
    "    elif data_collection_train_pred_Median_passward[index]==0 and data_collection_train_passward[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "recall = TP/(TP+FN)\n",
    "Precision = TP/(TP+FP)\n",
    "Accuracy = (TP+TN)/(TP+FP+FN+TN) \n",
    "F1 = (TP)/(TP+(0.5*(FP+FN)))\n",
    "\n",
    "print(\"recall:\" , recall)\n",
    "print(\"Precision:\" , Precision)\n",
    "print(\"Accuracy:\" , Accuracy)\n",
    "print(\"F1 Score:\" , F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3300cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [4, 5, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 4, 5, 6, 7, 8],\n",
       " [1, 2, 4],\n",
       " [1, 2, 3, 4, 5, 7, 8],\n",
       " [1, 2, 4, 5, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [4, 8],\n",
       " [1, 2, 7],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 7, 8],\n",
       " [2, 4, 6, 7, 8],\n",
       " [1, 2, 3, 4, 5, 6, 7, 8],\n",
       " [1, 3, 4, 7, 8],\n",
       " [1, 3, 5, 7]]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ##Privacy Policy Change Matrix:\n",
    "\n",
    "# ##Matrix creation:\n",
    "# matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "#                                                'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "#             ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "#             ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "#            ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "#             ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "#             ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "# matrix_data_security_Comparison['Phrase'] = [['we save your personal data','we are not collect your personal data']\n",
    "#                                  ,['we save your media','we are not collect your media']\n",
    "#                                  ,['we save your browsing history and preferences','we are not collect your browsing history and preferences']\n",
    "#                                  ,['we save your audio and recording','we are not collect your audio and recording']\n",
    "#                                  ,['we save your payments data','we are not collect your payments data']\n",
    "#                                  ,['we save your location and language','we are not collect your location and language']\n",
    "#                                  ,['we save your IP address and browser and device details','we are not collect your IP address and browser and device details']\n",
    "#                                  ,['we save your passwords','we are not collect your passwords']]\n",
    "\n",
    "# ##Filling the matrix:\n",
    "# websites_index = 0\n",
    "# line = 0\n",
    "# pred = 0\n",
    "# data_security_train_pred_Comparison = []\n",
    "# data_security_list_Comparison = []\n",
    "\n",
    "# for j in sequence_to_classify:\n",
    "#     for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "#         a = classifier(str(j), str(i))\n",
    "#         if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "#             pred = 1\n",
    "#         else:\n",
    "#             pred = 0 \n",
    "#         if pred == 1:\n",
    "#             data_security_list_Comparison.append(line+1)\n",
    "#         line += 1\n",
    "#     websites_index += 1\n",
    "#     data_security_train_pred_Comparison.append(data_security_list_Comparison)\n",
    "#     data_security_list_Comparison = []\n",
    "#     line = 0\n",
    "\n",
    "# data_security_train_pred_Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b017f16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1]]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##Matrix creation:\n",
    "matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_data_security_Comparison['Phrase'] = [['we save your personal data','we are not collect your personal data']]\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "data_security_train_pred_Comparison_personal = []\n",
    "data_security_list_Comparison = []\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "        a = classifier(str(j), str(i))\n",
    "        if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0 \n",
    "        if pred == 1:\n",
    "            data_security_list_Comparison.append(line+1)\n",
    "        line += 1\n",
    "    websites_index += 1\n",
    "    data_security_train_pred_Comparison_personal.append(data_security_list_Comparison)\n",
    "    data_security_list_Comparison = []\n",
    "    line = 0\n",
    "\n",
    "data_security_train_pred_Comparison_personal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2773e99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "##Matrix creation:\n",
    "matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_data_security_Comparison['Phrase'] = [['we save your media','we are not collect your media']]\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "data_security_train_pred_Comparison_media = []\n",
    "data_security_list_Comparison = []\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "        a = classifier(str(j), str(i))\n",
    "        if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0 \n",
    "        if pred == 1:\n",
    "            data_security_list_Comparison.append(line+1)\n",
    "        line += 1\n",
    "    websites_index += 1\n",
    "    data_security_train_pred_Comparison_media.append(data_security_list_Comparison)\n",
    "    data_security_list_Comparison = []\n",
    "    line = 0\n",
    "\n",
    "data_security_train_pred_Comparison_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a61854b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Matrix creation:\n",
    "matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_data_security_Comparison['Phrase'] = [['we save your browsing history and preferences','we are not collect your browsing history and preferences']]\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "data_security_train_pred_Comparison_browser = []\n",
    "data_security_list_Comparison = []\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "        a = classifier(str(j), str(i))\n",
    "        if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0 \n",
    "        if pred == 1:\n",
    "            data_security_list_Comparison.append(line+1)\n",
    "        line += 1\n",
    "    websites_index += 1\n",
    "    data_security_train_pred_Comparison_browser.append(data_security_list_Comparison)\n",
    "    data_security_list_Comparison = []\n",
    "    line = 0\n",
    "\n",
    "data_security_train_pred_Comparison_browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3c25245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Matrix creation:\n",
    "matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_data_security_Comparison['Phrase'] = [['we save your audio and recording','we are not collect your audio and recording']]\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "data_security_train_pred_Comparison_voice = []\n",
    "data_security_list_Comparison = []\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "        a = classifier(str(j), str(i))\n",
    "        if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0 \n",
    "        if pred == 1:\n",
    "            data_security_list_Comparison.append(line+1)\n",
    "        line += 1\n",
    "    websites_index += 1\n",
    "    data_security_train_pred_Comparison_voice.append(data_security_list_Comparison)\n",
    "    data_security_list_Comparison = []\n",
    "    line = 0\n",
    "\n",
    "data_security_train_pred_Comparison_voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "582dda6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1]]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Matrix creation:\n",
    "matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_data_security_Comparison['Phrase'] = [['we save your payments data','we are not collect your payments data']]\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "data_security_train_pred_Comparison_payments = []\n",
    "data_security_list_Comparison = []\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "        a = classifier(str(j), str(i))\n",
    "        if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0 \n",
    "        if pred == 1:\n",
    "            data_security_list_Comparison.append(line+1)\n",
    "        line += 1\n",
    "    websites_index += 1\n",
    "    data_security_train_pred_Comparison_payments.append(data_security_list_Comparison)\n",
    "    data_security_list_Comparison = []\n",
    "    line = 0\n",
    "\n",
    "data_security_train_pred_Comparison_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4c93e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1]]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Matrix creation:\n",
    "matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_data_security_Comparison['Phrase'] = [['we save your location and language','we are not collect your location and language']]\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "data_security_train_pred_Comparison_lng = []\n",
    "data_security_list_Comparison = []\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "        a = classifier(str(j), str(i))\n",
    "        if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0 \n",
    "        if pred == 1:\n",
    "            data_security_list_Comparison.append(line+1)\n",
    "        line += 1\n",
    "    websites_index += 1\n",
    "    data_security_train_pred_Comparison_lng.append(data_security_list_Comparison)\n",
    "    data_security_list_Comparison = []\n",
    "    line = 0\n",
    "\n",
    "data_security_train_pred_Comparison_lng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4e451f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1]]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Matrix creation:\n",
    "matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_data_security_Comparison['Phrase'] = [['we save your IP address and browser and device details','we are not collect your IP address and browser and device details']]\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "data_security_train_pred_Comparison_IP = []\n",
    "data_security_list_Comparison = []\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "        a = classifier(str(j), str(i))\n",
    "        if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0 \n",
    "        if pred == 1:\n",
    "            data_security_list_Comparison.append(line+1)\n",
    "        line += 1\n",
    "    websites_index += 1\n",
    "    data_security_train_pred_Comparison_IP.append(data_security_list_Comparison)\n",
    "    data_security_list_Comparison = []\n",
    "    line = 0\n",
    "\n",
    "data_security_train_pred_Comparison_IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d6a7c7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [1]]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Matrix creation:\n",
    "matrix_data_security_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_data_security_Comparison['Phrase'] = [['we save your passwords','we are not collect your passwords']]\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "data_security_train_pred_Comparison_password = []\n",
    "data_security_list_Comparison = []\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_data_security_Comparison[\"Phrase\"]:\n",
    "        a = classifier(str(j), str(i))\n",
    "        if matrix_data_security_Comparison['Phrase'][line][0] in a[\"labels\"][0]:\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0 \n",
    "        if pred == 1:\n",
    "            data_security_list_Comparison.append(line+1)\n",
    "        else:\n",
    "            data_security_list_Comparison.append(line)\n",
    "        line += 1\n",
    "    websites_index += 1\n",
    "    data_security_train_pred_Comparison_password.append(data_security_list_Comparison)\n",
    "    data_security_list_Comparison = []\n",
    "    line = 0\n",
    "\n",
    "data_security_train_pred_Comparison_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6542eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collection_train_personal = [[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]]\n",
    "data_collection_train_media = [[1],[1],[0],[0],[1],[1],[0],[0],[1],[1],[1],[0],[0],[1],[0],[1],[1],[1],[0],[1],[0],[1],[1],[0],[0],[0],[1],[1],[0],[1],[1],[1],[1],[1],[0],[0],[1],[0],[1],[1],[1],[0],[0],[0],[1],[0],[1],[0],[0]]\n",
    "data_collection_train_browser = [[1],[1],[1],[1],[1],[1],[0],[1],[1],[1],[1],[1],[1],[1],[1],[0],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]]\n",
    "data_collection_train_voice = [[1],[1],[0],[0],[1],[1],[1],[0],[0],[1],[0],[0],[0],[0],[0],[0],[1],[1],[0],[0],[0],[0],[1],[0],[0],[0],[1],[1],[0],[0],[0],[1],[0],[1],[1],[0],[1],[0],[1],[1],[0],[0],[0],[1],[0],[0],[1],[0],[0]]\n",
    "data_collection_train_payments = [[1],[1],[1],[0],[0],[1],[1],[1],[1],[1],[1],[1],[0],[0],[0],[1],[1],[1],[1],[0],[0],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[0],[1],[1],[1],[0],[1],[1],[0],[1],[1],[1],[1]]\n",
    "data_collection_train_location = [[1],[1],[1],[0],[1],[1],[1],[1],[1],[1],[1],[1],[0],[0],[0],[1],[1],[1],[0],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[0],[1],[0],[1],[1],[0],[0],[0],[1],[1],[1],[1],[1],[1]]\n",
    "data_collection_train_IP = [[1],[0],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[0],[1],[1],[1],[0],[1],[1],[1],[1],[1],[1],[1],[1],[0],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1],[1]]\n",
    "data_collection_train_passward = [[1],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[1],[0],[0],[1],[0],[1],[0],[0],[1],[1],[1],[1],[0],[0],[0],[1],[0],[1],[0],[1],[0],[1],[1],[0],[1],[0],[1],[0]]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3aa47727",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_personal:\n",
    "    if i==[]:\n",
    "        data_security_train_pred_Comparison_personal[index]=[0]\n",
    "    index +=1\n",
    "\n",
    "    \n",
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_media:\n",
    "    if i==[]:\n",
    "        data_security_train_pred_Comparison_media[index]=[0]\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_browser:\n",
    "    if i==[]:\n",
    "        data_security_train_pred_Comparison_browser[index]=[0]\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_voice:\n",
    "    if i==[]:\n",
    "        data_security_train_pred_Comparison_voice[index]=[0]\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_payments:\n",
    "    if i==[]:\n",
    "        data_security_train_pred_Comparison_payments[index]=[0]\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_lng:\n",
    "    if i==[]:\n",
    "        data_security_train_pred_Comparison_lng[index]=[0]\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_IP:\n",
    "    if i==[]:\n",
    "        data_security_train_pred_Comparison_IP[index]=[0]\n",
    "    index +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4af118fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.8392857142857143\n",
      "Precision: 0.7078313253012049\n",
      "Accuracy: 0.6377551020408163\n",
      "F1 Score: 0.7679738562091504\n"
     ]
    }
   ],
   "source": [
    "#Data Collection Parameter:\n",
    "index = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "for i in data_security_train_pred_Comparison_personal:\n",
    "    if data_security_train_pred_Comparison_personal[index]==[1] and data_collection_train_personal[index]==[1]:\n",
    "        TP +=1\n",
    "    elif data_security_train_pred_Comparison_personal[index]==[0] and data_collection_train_personal[index]==[0]:\n",
    "        TN +=1\n",
    "    elif data_security_train_pred_Comparison_personal[index]==[0] and data_collection_train_personal[index]==[1]:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_media:\n",
    "    if data_security_train_pred_Comparison_media[index]==[1] and data_collection_train_media[index]==[1]:\n",
    "        TP +=1\n",
    "    elif data_security_train_pred_Comparison_media[index]==[0] and data_collection_train_media[index]==[0]:\n",
    "        TN +=1\n",
    "    elif data_security_train_pred_Comparison_media[index]==[0] and data_collection_train_media[index]==[1]:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0\n",
    "for i in data_security_train_pred_Comparison_browser:\n",
    "    if data_security_train_pred_Comparison_browser[index]==[1] and data_collection_train_browser[index]==[1]:\n",
    "        TP +=1\n",
    "    elif data_security_train_pred_Comparison_browser[index]==[0] and data_collection_train_browser[index]==[0]:\n",
    "        TN +=1\n",
    "    elif data_security_train_pred_Comparison_browser[index]==[0] and data_collection_train_browser[index]==[1]:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_security_train_pred_Comparison_voice:\n",
    "    if data_security_train_pred_Comparison_voice[index]==[1] and data_collection_train_voice[index]==[1]:\n",
    "        TP +=1\n",
    "    elif data_security_train_pred_Comparison_voice[index]==[0] and data_collection_train_voice[index]==[0]:\n",
    "        TN +=1\n",
    "    elif data_security_train_pred_Comparison_voice[index]==[0] and data_collection_train_voice[index]==[1]:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0   \n",
    "for i in data_security_train_pred_Comparison_payments:\n",
    "    if data_security_train_pred_Comparison_payments[index]==[1] and data_collection_train_payments[index]==[1]:\n",
    "        TP +=1\n",
    "    elif data_security_train_pred_Comparison_payments[index]==[0] and data_collection_train_payments[index]==[0]:\n",
    "        TN +=1\n",
    "    elif data_security_train_pred_Comparison_payments[index]==[0] and data_collection_train_payments[index]==[1]:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_security_train_pred_Comparison_lng:\n",
    "    if data_security_train_pred_Comparison_lng[index]==[1] and data_collection_train_location[index]==[1]:\n",
    "        TP +=1\n",
    "    elif data_security_train_pred_Comparison_lng[index]==[0] and data_collection_train_location[index]==[0]:\n",
    "        TN +=1\n",
    "    elif data_security_train_pred_Comparison_lng[index]==[0] and data_collection_train_location[index]==[1]:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_security_train_pred_Comparison_IP:\n",
    "    if data_security_train_pred_Comparison_IP[index]==[1] and data_collection_train_IP[index]==[1]:\n",
    "        TP +=1\n",
    "    elif data_security_train_pred_Comparison_IP[index]==[0] and data_collection_train_IP[index]==[0]:\n",
    "        TN +=1\n",
    "    elif data_security_train_pred_Comparison_IP[index]==[0] and data_collection_train_IP[index]==[1]:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "index = 0    \n",
    "for i in data_security_train_pred_Comparison_password:\n",
    "    if data_security_train_pred_Comparison_password[index]==[1] and data_collection_train_passward[index]==[1]:\n",
    "        TP +=1\n",
    "    elif data_security_train_pred_Comparison_password[index]==[0] and data_collection_train_passward[index]==[0]:\n",
    "        TN +=1\n",
    "    elif data_security_train_pred_Comparison_password[index]==[0] and data_collection_train_passward[index]==[1]:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "    \n",
    "recall = TP/(TP+FN)\n",
    "Precision = TP/(TP+FP)\n",
    "Accuracy = (TP+TN)/(TP+FP+FN+TN) \n",
    "F1 = (TP)/(TP+(0.5*(FP+FN)))\n",
    "\n",
    "print(\"recall:\" , recall)\n",
    "print(\"Precision:\" , Precision)\n",
    "print(\"Accuracy:\" , Accuracy)\n",
    "print(\"F1 Score:\" , F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b66a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
