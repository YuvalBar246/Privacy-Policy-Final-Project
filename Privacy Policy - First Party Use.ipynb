{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798603de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,KFold, cross_val_predict, GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648c0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb81dc6",
   "metadata": {},
   "source": [
    "## Download All Policies - Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6d084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Privacy Policies download:\n",
    "websites = ['Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson']\n",
    "\n",
    "sequence_to_classify = []\n",
    "\n",
    "for i in websites:\n",
    "    try:\n",
    "        with open((i+\".txt\"), \"r\") as f:\n",
    "            i = f.readlines()\n",
    "            sequence_to_classify.append(i)\n",
    "    except:\n",
    "        with open((i+\".txt\"), \"r\", encoding='cp1252') as f:\n",
    "            i = f.readlines()\n",
    "            sequence_to_classify.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7e7d1",
   "metadata": {},
   "source": [
    "### Train Set Vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27697e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_party_use_train = [1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7707cd9b",
   "metadata": {},
   "source": [
    "### First Party Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2736c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the user information is being saved</th>\n",
       "      <th>We use your personal information</th>\n",
       "      <th>We collect and use your personal information</th>\n",
       "      <th>We will use the information we collect</th>\n",
       "      <th>We will use the information you provide</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Privacy Policy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Google</th>\n",
       "      <td>0.973002</td>\n",
       "      <td>0.98327</td>\n",
       "      <td>0.991912</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.97709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aws</th>\n",
       "      <td>0.929998</td>\n",
       "      <td>0.95334</td>\n",
       "      <td>0.966737</td>\n",
       "      <td>0.938838</td>\n",
       "      <td>0.940077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AliExpress</th>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.859369</td>\n",
       "      <td>0.950822</td>\n",
       "      <td>0.904863</td>\n",
       "      <td>0.898119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meta</th>\n",
       "      <td>0.969938</td>\n",
       "      <td>0.982271</td>\n",
       "      <td>0.989877</td>\n",
       "      <td>0.980696</td>\n",
       "      <td>0.978814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TikTok</th>\n",
       "      <td>0.877115</td>\n",
       "      <td>0.913555</td>\n",
       "      <td>0.951839</td>\n",
       "      <td>0.92532</td>\n",
       "      <td>0.918506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTube</th>\n",
       "      <td>0.951257</td>\n",
       "      <td>0.972655</td>\n",
       "      <td>0.972255</td>\n",
       "      <td>0.947119</td>\n",
       "      <td>0.966858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waze</th>\n",
       "      <td>0.911959</td>\n",
       "      <td>0.923871</td>\n",
       "      <td>0.960203</td>\n",
       "      <td>0.947474</td>\n",
       "      <td>0.956882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wix</th>\n",
       "      <td>0.919279</td>\n",
       "      <td>0.978406</td>\n",
       "      <td>0.987691</td>\n",
       "      <td>0.962101</td>\n",
       "      <td>0.946619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookings</th>\n",
       "      <td>0.981227</td>\n",
       "      <td>0.989663</td>\n",
       "      <td>0.995268</td>\n",
       "      <td>0.991088</td>\n",
       "      <td>0.988813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whatsapp</th>\n",
       "      <td>0.881537</td>\n",
       "      <td>0.887173</td>\n",
       "      <td>0.866845</td>\n",
       "      <td>0.809817</td>\n",
       "      <td>0.844999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>0.965624</td>\n",
       "      <td>0.968523</td>\n",
       "      <td>0.978178</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>0.971165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wolt</th>\n",
       "      <td>0.983332</td>\n",
       "      <td>0.995473</td>\n",
       "      <td>0.99604</td>\n",
       "      <td>0.994888</td>\n",
       "      <td>0.993511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Visa</th>\n",
       "      <td>0.941064</td>\n",
       "      <td>0.96877</td>\n",
       "      <td>0.980815</td>\n",
       "      <td>0.974124</td>\n",
       "      <td>0.969859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mastercard</th>\n",
       "      <td>0.971845</td>\n",
       "      <td>0.990564</td>\n",
       "      <td>0.994747</td>\n",
       "      <td>0.990087</td>\n",
       "      <td>0.989328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirBNB</th>\n",
       "      <td>0.909505</td>\n",
       "      <td>0.937571</td>\n",
       "      <td>0.96633</td>\n",
       "      <td>0.95325</td>\n",
       "      <td>0.945174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uber</th>\n",
       "      <td>0.975951</td>\n",
       "      <td>0.989889</td>\n",
       "      <td>0.991724</td>\n",
       "      <td>0.97981</td>\n",
       "      <td>0.97513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spotify</th>\n",
       "      <td>0.981905</td>\n",
       "      <td>0.980067</td>\n",
       "      <td>0.985789</td>\n",
       "      <td>0.97772</td>\n",
       "      <td>0.98198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>0.950754</td>\n",
       "      <td>0.98968</td>\n",
       "      <td>0.995642</td>\n",
       "      <td>0.985591</td>\n",
       "      <td>0.978187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wordpress</th>\n",
       "      <td>0.914648</td>\n",
       "      <td>0.968418</td>\n",
       "      <td>0.972885</td>\n",
       "      <td>0.966475</td>\n",
       "      <td>0.970198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instagram</th>\n",
       "      <td>0.955789</td>\n",
       "      <td>0.964022</td>\n",
       "      <td>0.972348</td>\n",
       "      <td>0.959353</td>\n",
       "      <td>0.965265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MacDonalds</th>\n",
       "      <td>0.996125</td>\n",
       "      <td>0.997253</td>\n",
       "      <td>0.998356</td>\n",
       "      <td>0.996828</td>\n",
       "      <td>0.996946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FDA</th>\n",
       "      <td>0.875043</td>\n",
       "      <td>0.911245</td>\n",
       "      <td>0.945481</td>\n",
       "      <td>0.932904</td>\n",
       "      <td>0.925872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oracle</th>\n",
       "      <td>0.954624</td>\n",
       "      <td>0.972988</td>\n",
       "      <td>0.984582</td>\n",
       "      <td>0.974885</td>\n",
       "      <td>0.971727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zara</th>\n",
       "      <td>0.962738</td>\n",
       "      <td>0.965521</td>\n",
       "      <td>0.984533</td>\n",
       "      <td>0.980653</td>\n",
       "      <td>0.976195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cocacola</th>\n",
       "      <td>0.940999</td>\n",
       "      <td>0.967978</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.970675</td>\n",
       "      <td>0.96317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Xiaomi</th>\n",
       "      <td>0.959204</td>\n",
       "      <td>0.966421</td>\n",
       "      <td>0.979032</td>\n",
       "      <td>0.977744</td>\n",
       "      <td>0.976597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nasdaq</th>\n",
       "      <td>0.918163</td>\n",
       "      <td>0.955474</td>\n",
       "      <td>0.971134</td>\n",
       "      <td>0.963184</td>\n",
       "      <td>0.957422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walmart</th>\n",
       "      <td>0.934293</td>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.976593</td>\n",
       "      <td>0.947187</td>\n",
       "      <td>0.932364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AirCanada</th>\n",
       "      <td>0.959364</td>\n",
       "      <td>0.985305</td>\n",
       "      <td>0.992824</td>\n",
       "      <td>0.98993</td>\n",
       "      <td>0.985528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lufthansa</th>\n",
       "      <td>0.953462</td>\n",
       "      <td>0.973721</td>\n",
       "      <td>0.982035</td>\n",
       "      <td>0.977323</td>\n",
       "      <td>0.97609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shopify</th>\n",
       "      <td>0.884392</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>0.979665</td>\n",
       "      <td>0.962094</td>\n",
       "      <td>0.955754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netflix</th>\n",
       "      <td>0.935696</td>\n",
       "      <td>0.949606</td>\n",
       "      <td>0.980308</td>\n",
       "      <td>0.955222</td>\n",
       "      <td>0.934927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>0.840388</td>\n",
       "      <td>0.895083</td>\n",
       "      <td>0.926001</td>\n",
       "      <td>0.891224</td>\n",
       "      <td>0.869086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Starbucks</th>\n",
       "      <td>0.992773</td>\n",
       "      <td>0.99544</td>\n",
       "      <td>0.997604</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.995278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shoppers</th>\n",
       "      <td>0.88904</td>\n",
       "      <td>0.966125</td>\n",
       "      <td>0.98023</td>\n",
       "      <td>0.971359</td>\n",
       "      <td>0.962915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decathlon</th>\n",
       "      <td>0.90243</td>\n",
       "      <td>0.94653</td>\n",
       "      <td>0.976726</td>\n",
       "      <td>0.953517</td>\n",
       "      <td>0.940452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waltdisney</th>\n",
       "      <td>0.987612</td>\n",
       "      <td>0.991845</td>\n",
       "      <td>0.994796</td>\n",
       "      <td>0.98834</td>\n",
       "      <td>0.987017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AmericanEagle</th>\n",
       "      <td>0.962541</td>\n",
       "      <td>0.950643</td>\n",
       "      <td>0.982222</td>\n",
       "      <td>0.976294</td>\n",
       "      <td>0.968377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lululemon</th>\n",
       "      <td>0.956905</td>\n",
       "      <td>0.986183</td>\n",
       "      <td>0.991642</td>\n",
       "      <td>0.98714</td>\n",
       "      <td>0.984963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAP</th>\n",
       "      <td>0.985007</td>\n",
       "      <td>0.990061</td>\n",
       "      <td>0.988834</td>\n",
       "      <td>0.985583</td>\n",
       "      <td>0.985761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JetBrains</th>\n",
       "      <td>0.91645</td>\n",
       "      <td>0.951659</td>\n",
       "      <td>0.983449</td>\n",
       "      <td>0.96777</td>\n",
       "      <td>0.963008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MySQLCode</th>\n",
       "      <td>0.727202</td>\n",
       "      <td>0.76835</td>\n",
       "      <td>0.891993</td>\n",
       "      <td>0.805193</td>\n",
       "      <td>0.783382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cadens</th>\n",
       "      <td>0.763571</td>\n",
       "      <td>0.729896</td>\n",
       "      <td>0.991186</td>\n",
       "      <td>0.983416</td>\n",
       "      <td>0.974422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EpicGames</th>\n",
       "      <td>0.935965</td>\n",
       "      <td>0.925217</td>\n",
       "      <td>0.957598</td>\n",
       "      <td>0.918704</td>\n",
       "      <td>0.895404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unitedHealthGroup</th>\n",
       "      <td>0.920272</td>\n",
       "      <td>0.915327</td>\n",
       "      <td>0.952033</td>\n",
       "      <td>0.931039</td>\n",
       "      <td>0.91617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slack</th>\n",
       "      <td>0.947611</td>\n",
       "      <td>0.959347</td>\n",
       "      <td>0.978461</td>\n",
       "      <td>0.963315</td>\n",
       "      <td>0.963105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesForce</th>\n",
       "      <td>0.94468</td>\n",
       "      <td>0.958814</td>\n",
       "      <td>0.977464</td>\n",
       "      <td>0.967708</td>\n",
       "      <td>0.954873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPMorgan</th>\n",
       "      <td>0.941706</td>\n",
       "      <td>0.557431</td>\n",
       "      <td>0.994559</td>\n",
       "      <td>0.98897</td>\n",
       "      <td>0.988134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JohnsonAndJohnson</th>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.972684</td>\n",
       "      <td>0.980058</td>\n",
       "      <td>0.977921</td>\n",
       "      <td>0.977289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  the user information is being saved  \\\n",
       "Privacy Policy                                          \n",
       "Google                                       0.973002   \n",
       "Aws                                          0.929998   \n",
       "AliExpress                                     0.7962   \n",
       "Meta                                         0.969938   \n",
       "TikTok                                       0.877115   \n",
       "YouTube                                      0.951257   \n",
       "Waze                                         0.911959   \n",
       "Wix                                          0.919279   \n",
       "Bookings                                     0.981227   \n",
       "whatsapp                                     0.881537   \n",
       "apple                                        0.965624   \n",
       "wolt                                         0.983332   \n",
       "Visa                                         0.941064   \n",
       "Mastercard                                   0.971845   \n",
       "AirBNB                                       0.909505   \n",
       "uber                                         0.975951   \n",
       "Spotify                                      0.981905   \n",
       "samsung                                      0.950754   \n",
       "Wordpress                                    0.914648   \n",
       "instagram                                    0.955789   \n",
       "MacDonalds                                   0.996125   \n",
       "FDA                                          0.875043   \n",
       "Oracle                                       0.954624   \n",
       "Zara                                         0.962738   \n",
       "cocacola                                     0.940999   \n",
       "Xiaomi                                       0.959204   \n",
       "Nasdaq                                       0.918163   \n",
       "Walmart                                      0.934293   \n",
       "AirCanada                                    0.959364   \n",
       "Lufthansa                                    0.953462   \n",
       "shopify                                      0.884392   \n",
       "Netflix                                      0.935696   \n",
       "adobe                                        0.840388   \n",
       "Starbucks                                    0.992773   \n",
       "Shoppers                                      0.88904   \n",
       "Decathlon                                     0.90243   \n",
       "waltdisney                                   0.987612   \n",
       "AmericanEagle                                0.962541   \n",
       "lululemon                                    0.956905   \n",
       "SAP                                          0.985007   \n",
       "JetBrains                                     0.91645   \n",
       "MySQLCode                                    0.727202   \n",
       "Cadens                                       0.763571   \n",
       "EpicGames                                    0.935965   \n",
       "unitedHealthGroup                            0.920272   \n",
       "Slack                                        0.947611   \n",
       "SalesForce                                    0.94468   \n",
       "JPMorgan                                     0.941706   \n",
       "JohnsonAndJohnson                            0.924812   \n",
       "\n",
       "                  We use your personal information  \\\n",
       "Privacy Policy                                       \n",
       "Google                                     0.98327   \n",
       "Aws                                        0.95334   \n",
       "AliExpress                                0.859369   \n",
       "Meta                                      0.982271   \n",
       "TikTok                                    0.913555   \n",
       "YouTube                                   0.972655   \n",
       "Waze                                      0.923871   \n",
       "Wix                                       0.978406   \n",
       "Bookings                                  0.989663   \n",
       "whatsapp                                  0.887173   \n",
       "apple                                     0.968523   \n",
       "wolt                                      0.995473   \n",
       "Visa                                       0.96877   \n",
       "Mastercard                                0.990564   \n",
       "AirBNB                                    0.937571   \n",
       "uber                                      0.989889   \n",
       "Spotify                                   0.980067   \n",
       "samsung                                    0.98968   \n",
       "Wordpress                                 0.968418   \n",
       "instagram                                 0.964022   \n",
       "MacDonalds                                0.997253   \n",
       "FDA                                       0.911245   \n",
       "Oracle                                    0.972988   \n",
       "Zara                                      0.965521   \n",
       "cocacola                                  0.967978   \n",
       "Xiaomi                                    0.966421   \n",
       "Nasdaq                                    0.955474   \n",
       "Walmart                                   0.963568   \n",
       "AirCanada                                 0.985305   \n",
       "Lufthansa                                 0.973721   \n",
       "shopify                                   0.961783   \n",
       "Netflix                                   0.949606   \n",
       "adobe                                     0.895083   \n",
       "Starbucks                                  0.99544   \n",
       "Shoppers                                  0.966125   \n",
       "Decathlon                                  0.94653   \n",
       "waltdisney                                0.991845   \n",
       "AmericanEagle                             0.950643   \n",
       "lululemon                                 0.986183   \n",
       "SAP                                       0.990061   \n",
       "JetBrains                                 0.951659   \n",
       "MySQLCode                                  0.76835   \n",
       "Cadens                                    0.729896   \n",
       "EpicGames                                 0.925217   \n",
       "unitedHealthGroup                         0.915327   \n",
       "Slack                                     0.959347   \n",
       "SalesForce                                0.958814   \n",
       "JPMorgan                                  0.557431   \n",
       "JohnsonAndJohnson                         0.972684   \n",
       "\n",
       "                  We collect and use your personal information  \\\n",
       "Privacy Policy                                                   \n",
       "Google                                                0.991912   \n",
       "Aws                                                   0.966737   \n",
       "AliExpress                                            0.950822   \n",
       "Meta                                                  0.989877   \n",
       "TikTok                                                0.951839   \n",
       "YouTube                                               0.972255   \n",
       "Waze                                                  0.960203   \n",
       "Wix                                                   0.987691   \n",
       "Bookings                                              0.995268   \n",
       "whatsapp                                              0.866845   \n",
       "apple                                                 0.978178   \n",
       "wolt                                                   0.99604   \n",
       "Visa                                                  0.980815   \n",
       "Mastercard                                            0.994747   \n",
       "AirBNB                                                 0.96633   \n",
       "uber                                                  0.991724   \n",
       "Spotify                                               0.985789   \n",
       "samsung                                               0.995642   \n",
       "Wordpress                                             0.972885   \n",
       "instagram                                             0.972348   \n",
       "MacDonalds                                            0.998356   \n",
       "FDA                                                   0.945481   \n",
       "Oracle                                                0.984582   \n",
       "Zara                                                  0.984533   \n",
       "cocacola                                              0.982759   \n",
       "Xiaomi                                                0.979032   \n",
       "Nasdaq                                                0.971134   \n",
       "Walmart                                               0.976593   \n",
       "AirCanada                                             0.992824   \n",
       "Lufthansa                                             0.982035   \n",
       "shopify                                               0.979665   \n",
       "Netflix                                               0.980308   \n",
       "adobe                                                 0.926001   \n",
       "Starbucks                                             0.997604   \n",
       "Shoppers                                               0.98023   \n",
       "Decathlon                                             0.976726   \n",
       "waltdisney                                            0.994796   \n",
       "AmericanEagle                                         0.982222   \n",
       "lululemon                                             0.991642   \n",
       "SAP                                                   0.988834   \n",
       "JetBrains                                             0.983449   \n",
       "MySQLCode                                             0.891993   \n",
       "Cadens                                                0.991186   \n",
       "EpicGames                                             0.957598   \n",
       "unitedHealthGroup                                     0.952033   \n",
       "Slack                                                 0.978461   \n",
       "SalesForce                                            0.977464   \n",
       "JPMorgan                                              0.994559   \n",
       "JohnsonAndJohnson                                     0.980058   \n",
       "\n",
       "                  We will use the information we collect  \\\n",
       "Privacy Policy                                             \n",
       "Google                                          0.982043   \n",
       "Aws                                             0.938838   \n",
       "AliExpress                                      0.904863   \n",
       "Meta                                            0.980696   \n",
       "TikTok                                           0.92532   \n",
       "YouTube                                         0.947119   \n",
       "Waze                                            0.947474   \n",
       "Wix                                             0.962101   \n",
       "Bookings                                        0.991088   \n",
       "whatsapp                                        0.809817   \n",
       "apple                                           0.969072   \n",
       "wolt                                            0.994888   \n",
       "Visa                                            0.974124   \n",
       "Mastercard                                      0.990087   \n",
       "AirBNB                                           0.95325   \n",
       "uber                                             0.97981   \n",
       "Spotify                                          0.97772   \n",
       "samsung                                         0.985591   \n",
       "Wordpress                                       0.966475   \n",
       "instagram                                       0.959353   \n",
       "MacDonalds                                      0.996828   \n",
       "FDA                                             0.932904   \n",
       "Oracle                                          0.974885   \n",
       "Zara                                            0.980653   \n",
       "cocacola                                        0.970675   \n",
       "Xiaomi                                          0.977744   \n",
       "Nasdaq                                          0.963184   \n",
       "Walmart                                         0.947187   \n",
       "AirCanada                                        0.98993   \n",
       "Lufthansa                                       0.977323   \n",
       "shopify                                         0.962094   \n",
       "Netflix                                         0.955222   \n",
       "adobe                                           0.891224   \n",
       "Starbucks                                       0.995333   \n",
       "Shoppers                                        0.971359   \n",
       "Decathlon                                       0.953517   \n",
       "waltdisney                                       0.98834   \n",
       "AmericanEagle                                   0.976294   \n",
       "lululemon                                        0.98714   \n",
       "SAP                                             0.985583   \n",
       "JetBrains                                        0.96777   \n",
       "MySQLCode                                       0.805193   \n",
       "Cadens                                          0.983416   \n",
       "EpicGames                                       0.918704   \n",
       "unitedHealthGroup                               0.931039   \n",
       "Slack                                           0.963315   \n",
       "SalesForce                                      0.967708   \n",
       "JPMorgan                                         0.98897   \n",
       "JohnsonAndJohnson                               0.977921   \n",
       "\n",
       "                  We will use the information you provide  \n",
       "Privacy Policy                                             \n",
       "Google                                            0.97709  \n",
       "Aws                                              0.940077  \n",
       "AliExpress                                       0.898119  \n",
       "Meta                                             0.978814  \n",
       "TikTok                                           0.918506  \n",
       "YouTube                                          0.966858  \n",
       "Waze                                             0.956882  \n",
       "Wix                                              0.946619  \n",
       "Bookings                                         0.988813  \n",
       "whatsapp                                         0.844999  \n",
       "apple                                            0.971165  \n",
       "wolt                                             0.993511  \n",
       "Visa                                             0.969859  \n",
       "Mastercard                                       0.989328  \n",
       "AirBNB                                           0.945174  \n",
       "uber                                              0.97513  \n",
       "Spotify                                           0.98198  \n",
       "samsung                                          0.978187  \n",
       "Wordpress                                        0.970198  \n",
       "instagram                                        0.965265  \n",
       "MacDonalds                                       0.996946  \n",
       "FDA                                              0.925872  \n",
       "Oracle                                           0.971727  \n",
       "Zara                                             0.976195  \n",
       "cocacola                                          0.96317  \n",
       "Xiaomi                                           0.976597  \n",
       "Nasdaq                                           0.957422  \n",
       "Walmart                                          0.932364  \n",
       "AirCanada                                        0.985528  \n",
       "Lufthansa                                         0.97609  \n",
       "shopify                                          0.955754  \n",
       "Netflix                                          0.934927  \n",
       "adobe                                            0.869086  \n",
       "Starbucks                                        0.995278  \n",
       "Shoppers                                         0.962915  \n",
       "Decathlon                                        0.940452  \n",
       "waltdisney                                       0.987017  \n",
       "AmericanEagle                                    0.968377  \n",
       "lululemon                                        0.984963  \n",
       "SAP                                              0.985761  \n",
       "JetBrains                                        0.963008  \n",
       "MySQLCode                                        0.783382  \n",
       "Cadens                                           0.974422  \n",
       "EpicGames                                        0.895404  \n",
       "unitedHealthGroup                                 0.91617  \n",
       "Slack                                            0.963105  \n",
       "SalesForce                                       0.954873  \n",
       "JPMorgan                                         0.988134  \n",
       "JohnsonAndJohnson                                0.977289  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##first_party_use Matrix:\n",
    "\n",
    "Phrases = ['Privacy Policy'\n",
    "           ,'the user information is being saved'\n",
    "           ,'We use your personal information'\n",
    "           ,'We collect and use your personal information'\n",
    "           ,'We will use the information we collect'\n",
    "           ,'We will use the information you provide']\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_first_party_ML = pd.DataFrame(columns = Phrases)\n",
    "matrix_first_party_ML['Privacy Policy'] = websites\n",
    "matrix_first_party_ML.set_index('Privacy Policy', inplace=True)\n",
    "\n",
    "##Filling the matrix:\n",
    "line = 0\n",
    "for j in sequence_to_classify:\n",
    "    for i in matrix_first_party_ML:\n",
    "        matrix_first_party_ML.loc[websites[line],i] = classifier(str(j), str(i))[\"scores\"][0]\n",
    "    line += 1\n",
    "    \n",
    "matrix_first_party_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf7ced",
   "metadata": {},
   "source": [
    "### Test The Model - ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ffb93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifaier: [1 1 1 0 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.93        15\n",
      "   macro avg       0.50      0.47      0.48        15\n",
      "weighted avg       1.00      0.93      0.97        15\n",
      "\n",
      "Random Forest Classifaier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "Logistic Reg Classifier: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "SVM: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/yuvalba/opt/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n",
      "neural_network: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(matrix_policy_change, policy_change_train\n",
    "#                                                     , test_size=0.5, random_state=42)\n",
    "\n",
    "# Manual division so we will have all options (1/0) at both groups\n",
    "X_train = matrix_first_party_ML.iloc[:35,:] \n",
    "X_test = matrix_first_party_ML.iloc[34:,:]\n",
    "y_train = first_party_use_train[:35]\n",
    "y_test = first_party_use_train[34:]\n",
    "\n",
    "##Decission Tree Classifaier\n",
    "regressor_tree = DecisionTreeClassifier()\n",
    "regressor_tree = regressor_tree.fit(X_train, y_train)\n",
    "pred_tree = regressor_tree.predict(X_test)\n",
    "print('Decission Tree Classifaier:', pred_tree)\n",
    "print(classification_report(y_test, pred_tree))\n",
    "\n",
    "##Random Forest Classifaier\n",
    "regressor_forest = RandomForestClassifier()\n",
    "regressor_forest = regressor_forest.fit(X_train, y_train)\n",
    "pred_forest = regressor_forest.predict(X_test).round()\n",
    "print('Random Forest Classifaier:', pred_forest)\n",
    "print(classification_report(y_test, pred_forest))\n",
    "\n",
    "##Logistic Reg Classifier\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "pred_clf = clf.predict(X_test)\n",
    "print('Logistic Reg Classifier:', pred_clf)\n",
    "print(classification_report(y_test, pred_clf))\n",
    "\n",
    "##SVM\n",
    "SVM = SVC(kernel='linear')\n",
    "SVM = SVM.fit(X_train, y_train)\n",
    "pred_SVM = SVM.predict(X_test)\n",
    "print('SVM:', pred_SVM)\n",
    "print(classification_report(y_test, pred_SVM))\n",
    "\n",
    "##KNN\n",
    "KNN = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "KNN = KNN.fit(X_train, y_train)\n",
    "pred_KNN = KNN.predict(X_test)\n",
    "print('KNN:', pred_KNN)\n",
    "print(classification_report(y_test, pred_KNN))\n",
    "\n",
    "##neural_network\n",
    "neural_network = MLPClassifier(random_state=1, max_iter=300)\n",
    "neural_network = neural_network.fit(X_train, y_train)\n",
    "pred_neural_network = neural_network.predict(X_test)\n",
    "print('neural_network:', pred_neural_network)\n",
    "print(classification_report(y_test, pred_neural_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3300cbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##first_party use Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_first_party_Comparison = pd.DataFrame(columns = ['Phrase',\n",
    "                                               'Google','Aws','AliExpress','Meta','TikTok','YouTube','Waze','Wix','Bookings','whatsapp'\n",
    "            ,'apple','wolt','Visa','Mastercard','AirBNB','uber','Spotify','samsung','Wordpress','instagram'\n",
    "            ,'MacDonalds','FDA','Oracle','Zara','cocacola','Xiaomi','Nasdaq','Walmart'\n",
    "           ,'AirCanada','Lufthansa','shopify','Netflix','adobe','Starbucks','Shoppers','Decathlon','waltdisney'\n",
    "            ,'AmericanEagle','lululemon','SAP','JetBrains','MySQLCode','Cadens','EpicGames'\n",
    "            ,'unitedHealthGroup','Slack','SalesForce','JPMorgan','JohnsonAndJohnson'])\n",
    "matrix_first_party_Comparison['Phrase'] = ['First Party Use']\n",
    "\n",
    "##Filling the matrix:\n",
    "websites_index = 0\n",
    "line = 0\n",
    "pred = 0\n",
    "first_party_train_pred_Comparison = []\n",
    "c = ['We use your personal information','We are not using your personal information']\n",
    "\n",
    "for j in sequence_to_classify:\n",
    "    a = classifier(str(j),c)\n",
    "    if a[\"labels\"][0]==c[0] :#and a[\"scores\"][0]>0.6:\n",
    "        pred = 1\n",
    "    else:\n",
    "        pred = 0  \n",
    "    matrix_first_party_Comparison[websites[websites_index]].loc[line] = pred\n",
    "    first_party_train_pred_Comparison.append(pred)\n",
    "    websites_index += 1\n",
    "    pred = 0\n",
    "\n",
    "first_party_train_pred_Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "242290dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 1.0\n",
      "specificity: 0.0\n",
      "Precision: 0.9795918367346939\n",
      "Accuracy: 0.9795918367346939\n",
      "F1 Score: 0.9896907216494846\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "for i in first_party_use_train:\n",
    "    if first_party_train_pred_Comparison[index]==1 and first_party_use_train[index]==1:\n",
    "        TP +=1\n",
    "    elif first_party_train_pred_Comparison[index]==0 and first_party_use_train[index]==0:\n",
    "        TN +=1\n",
    "    elif first_party_train_pred_Comparison[index]==0 and first_party_use_train[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "specificity = TN/(TN+FP)\n",
    "Precision = TP/(TP+FP)\n",
    "Accuracy = (TP+TN)/(TP+FP+FN+TN) \n",
    "F1 = (TP)/(TP+(0.5*(FP+FN)))\n",
    "\n",
    "print(\"recall:\" , recall)\n",
    "print(\"specificity:\" , specificity)\n",
    "print(\"Precision:\" , Precision)\n",
    "print(\"Accuracy:\" , Accuracy)\n",
    "print(\"F1 Score:\" , F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da470bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Privacy Policy Change Matrix:\n",
    "\n",
    "##Matrix creation:\n",
    "matrix_first_party_Median = matrix_first_party_ML.transpose()\n",
    "\n",
    "#add the avg and median rows:\n",
    "matrix_first_party_Median.loc['Median'] =  matrix_first_party_Median.median()\n",
    "matrix_first_party_Median.loc['Median']['Privacy Policy'] = 'Median'\n",
    "\n",
    "## Print the matrix:\n",
    "matrix_first_party_Median\n",
    "\n",
    "first_party_train_pred_Median = []\n",
    "websites_index = 0\n",
    "\n",
    "for i in matrix_first_party_Median:\n",
    "    num = matrix_first_party_Median[websites[websites_index]].loc['Median']\n",
    "    if num >0.65:\n",
    "        first_party_train_pred_Median.append(1)\n",
    "    else:\n",
    "        first_party_train_pred_Median.append(0)\n",
    "    websites_index += 1\n",
    "    \n",
    "first_party_train_pred_Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06905405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 1.0\n",
      "Precision: 0.9795918367346939\n",
      "Accuracy: 0.9795918367346939\n",
      "F1 Score: 0.9896907216494846\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "TP = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "\n",
    "for i in first_party_use_train:\n",
    "    if first_party_train_pred_Median[index]==1 and first_party_use_train[index]==1:\n",
    "        TP +=1\n",
    "    elif first_party_train_pred_Median[index]==0 and first_party_use_train[index]==0:\n",
    "        TN +=1\n",
    "    elif first_party_train_pred_Median[index]==0 and first_party_use_train[index]==1:\n",
    "        FN +=1\n",
    "    else:\n",
    "        FP +=1\n",
    "    index +=1\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "Precision = TP/(TP+FP)\n",
    "Accuracy = (TP+TN)/(TP+FP+FN+TN) \n",
    "F1 = (TP)/(TP+(0.5*(FP+FN)))\n",
    "\n",
    "print(\"recall:\" , recall)\n",
    "print(\"Precision:\" , Precision)\n",
    "print(\"Accuracy:\" , Accuracy)\n",
    "print(\"F1 Score:\" , F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ba5352",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
